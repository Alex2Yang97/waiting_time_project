{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:\\\\jupyter files\\\\data_waiting_time_project\\\\preprocess_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data_part1 = pd.read_csv(data_path + 'data_part1.csv', index_col = 0)\n",
    "data_part2 = pd.read_csv(data_path + 'data_part2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把字符串转成datetime\n",
    "def str_to_Datetime(st):\n",
    "    dt = datetime.datetime.strptime(st, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = ['Scheduled_duration', 'Actual_duration',\n",
    "               'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "               'MU_total', 'MUCoeff_total', 'Interval_scheduled']\n",
    "\n",
    "# RadiationId\n",
    "feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "                'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                'TreatmentOrientation', 'FractionNumber',\n",
    "                'UserName', 'CourseId', 'ResourceSerNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为需要进行onehot encoding，所以在拼接数据之前，先进行数据格式的处理\n",
    "for col in feature_cate:\n",
    "    try:\n",
    "        data_part1[col].fillna('Unknown', inplace = True)\n",
    "        data_part1[col] = data_part1[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data_part2[col].fillna('Unknown', inplace = True)\n",
    "        data_part2[col] = data_part2[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for col in feature_num:\n",
    "    try:\n",
    "        data_part1.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data_part2.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# data_num = log1p(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "              n_values=None, sparse=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoder\n",
    "label_encoder_dxt_AliasName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_dxt_AliasName.fit(data_part1.dxt_AliasName.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_Sex = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_Sex.fit(data_part1.Sex.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_AliasSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_AliasSerNum.fit(data_part1.AliasSerNum.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_month = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_month.fit(data_part1.month.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_week = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_week.fit(data_part1.week.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_hour = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_hour.fit(data_part1.hour.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_DoctorSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_DoctorSerNum.fit(data_part1.DoctorSerNum.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_TreatmentOrientation = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_TreatmentOrientation.fit(data_part1.TreatmentOrientation.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_FractionNumber = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_FractionNumber.fit(data_part2.FractionNumber.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_UserName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_UserName.fit(data_part2.UserName.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_CourseId = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_CourseId.fit(data_part2.CourseId.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_ResourceSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_ResourceSerNum.fit(data_part2.ResourceSerNum.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### categorical feature 不同取值的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_num = ['Scheduled_duration', 'Actual_duration', 'Actual_duration',\n",
    "#                'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "#                'MU_total', 'MUCoeff_total']\n",
    "\n",
    "# # RadiationId\n",
    "# feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "#                 'month', 'week', 'hour', 'DoctorSerNum', \n",
    "#                 'TreatmentOrientation', 'FractionNumber',\n",
    "#                 'UserName', 'CourseId', 'ResourceSerNum']\n",
    "\n",
    "# feature_count1 = pd.DataFrame({})\n",
    "# for col in feature_cate:\n",
    "#     try:\n",
    "#         n = len(data_part1[col].unique())\n",
    "#         feature_count1[col] = [n]\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "# feature_count2 = pd.DataFrame({})\n",
    "# for col in feature_cate:\n",
    "#     try:\n",
    "#         n = len(data_part2[col].unique())\n",
    "#         feature_count2[col] = [n]\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 with one appointment\n",
      "1900 with more appointment\n",
      "\n",
      "500 appointment data\n",
      "\n",
      "1000 appointment data\n",
      "\n",
      "1500 appointment data\n"
     ]
    }
   ],
   "source": [
    "data_part1_grouped = data_part1.iloc[: 10000].groupby('AppointmentSerNum')\n",
    "\n",
    "appt_one_list = []\n",
    "appt_more_list = []\n",
    "for appt in data_part1_grouped.groups.keys():\n",
    "    sample = data_part1_grouped.get_group(appt)\n",
    "    if sample.shape[0] == 1:\n",
    "        appt_one_list.append(appt)\n",
    "print(f'{len(appt_one_list)} with one appointment')\n",
    "\n",
    "appt_more_list = [i for i in data_part1_grouped.groups.keys() if i not in appt_one_list]\n",
    "print(f'{len(appt_more_list)} with more appointment')\n",
    "\n",
    "\n",
    "# key_list = list(data_part1_grouped.groups.keys())\n",
    "data_part1_new = pd.DataFrame({})\n",
    "for i in range(len(appt_more_list)):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f'\\n{i+1} appointment data')\n",
    "        \n",
    "    sample = data_part1_grouped.get_group(appt_more_list[i])\n",
    "    new_appt = pd.DataFrame({\n",
    "        'PatientSerNum': sample.PatientSerNum.tolist()[0],\n",
    "        'AppointmentSerNum': sample.AppointmentSerNum.tolist()[0],\n",
    "        'Sex': sample.Sex.tolist()[0],\n",
    "        'age': sample.age.tolist()[0],\n",
    "        'DoctorSerNum': sample.DoctorSerNum.tolist()[0],\n",
    "        'month': sample.month.tolist()[0],\n",
    "        'date': sample.date.tolist()[0],\n",
    "        'week': sample.week.tolist()[0],\n",
    "        'hour': sample.hour.tolist()[0],\n",
    "        'Scheduled_duration': sample.Scheduled_duration.tolist()[0],\n",
    "        'Actual_duration': sample.Actual_duration.tolist()[0],\n",
    "        'ScheduledStartTime': sample.ScheduledStartTime.tolist()[0],\n",
    "        'ScheduledEndTime': sample.ScheduledEndTime.tolist()[0],\n",
    "        'ActualStartDate': sample.ActualStartDate.tolist()[0],\n",
    "        'ActualEndDate': sample.ActualEndDate.tolist()[0],\n",
    "        \n",
    "        'dxt_AliasName': [list(set(sample.dxt_AliasName.tolist()))], \n",
    "        'AliasSerNum': [list(set(sample.AliasSerNum.tolist()))], \n",
    "        'CourseSerNum': [list(set(sample.CourseSerNum.tolist()))], \n",
    "        'PlanSerNum': [list(set(sample.PlanSerNum.tolist()))], \n",
    "        'TreatmentOrientation': [list(set(sample.TreatmentOrientation.tolist()))],\n",
    "        \n",
    "    })\n",
    "    \n",
    "    data_part1_new = pd.concat([data_part1_new, new_appt], axis = 0)\n",
    "data_part1_new.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime'], inplace = True)\n",
    "data_part1_new.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 with one treatment\n",
      "3118 with more treatment\n",
      "\n",
      "500 treatment data\n",
      "\n",
      "1000 treatment data\n",
      "\n",
      "1500 treatment data\n",
      "\n",
      "2000 treatment data\n",
      "\n",
      "2500 treatment data\n",
      "\n",
      "3000 treatment data\n"
     ]
    }
   ],
   "source": [
    "data_part2_grouped = data_part2.iloc[: 10000].groupby(['PatientSerNum', 'date'])\n",
    "\n",
    "treat_one_list = []\n",
    "treat_more_list = []\n",
    "for k in data_part2_grouped.groups.keys():\n",
    "    sample = data_part2_grouped.get_group(k)\n",
    "    if sample.shape[0] == 1:\n",
    "        treat_one_list.append(appt)\n",
    "print(f'{len(treat_one_list)} with one treatment')\n",
    "\n",
    "treat_more_list = [i for i in data_part2_grouped.groups.keys() if i not in treat_one_list]\n",
    "print(f'{len(treat_more_list)} with more treatment')\n",
    "\n",
    "# key_list = list(data_part2_grouped.groups.keys())\n",
    "data_part2_new = pd.DataFrame({})\n",
    "for i in range(len(treat_more_list)):\n",
    "    if (i+1) % 500 == 0:\n",
    "        print(f'\\n{i+1} treatment data')\n",
    "        \n",
    "    sample = data_part2_grouped.get_group(treat_more_list[i])\n",
    "    try:\n",
    "        new_treat = pd.DataFrame({\n",
    "            'PatientSerNum': sample.PatientSerNum.tolist()[0],\n",
    "            'FractionNumber': sample.FractionNumber.tolist()[0],\n",
    "            'date': sample.date.tolist()[0],\n",
    "\n",
    "            'UserName': [list(set(sample.UserName.tolist()))], \n",
    "            'RadiationSerNum': [list(set(sample.RadiationSerNum.tolist()))], \n",
    "            'RadiationId': [list(set(sample.RadiationId.tolist()))], \n",
    "            'ResourceSerNum': [list(set(sample.ResourceSerNum.tolist()))], \n",
    "            'CourseId': [list(set(sample.CourseId.tolist()))],\n",
    "\n",
    "            'ImagesTaken_total': sum(sample.ImagesTaken.tolist()),\n",
    "            'MU_total': sum(sample.MU.tolist()),\n",
    "            'MUCoeff_total': sum(sample.MUCoeff.tolist()),\n",
    "            'TreatmentTime_total': sum(sample.TreatmentTime.tolist()),\n",
    "        })\n",
    "        data_part2_new = pd.concat([data_part2_new, new_treat], axis = 0)\n",
    "    except:\n",
    "        print(treat_more_list[i])\n",
    "    \n",
    "    \n",
    "data_part2_new.sort_values(by = ['PatientSerNum', 'date', 'FractionNumber'], inplace = True)\n",
    "data_part2_new.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data_part1_new is (1900, 20)\n",
      "The shape of data_part1_new is (3118, 12)\n",
      "The shape of data is (584, 30)\n"
     ]
    }
   ],
   "source": [
    "data_part1_new.head()\n",
    "print(f'The shape of data_part1_new is {data_part1_new.shape}')\n",
    "print(f'The shape of data_part1_new is {data_part2_new.shape}')\n",
    "\n",
    "DATA = pd.merge(data_part1_new, data_part2_new, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "DATA.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'FractionNumber'], inplace = True)\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series data 47\n"
     ]
    }
   ],
   "source": [
    "DATA_grouped = DATA.groupby('PatientSerNum')\n",
    "\n",
    "series_data = []\n",
    "for pat in DATA_grouped.groups.keys():\n",
    "    if DATA_grouped.get_group(pat).shape[0] > 2:\n",
    "        series_data.append(pat)\n",
    "print(f'series data {len(series_data)}')\n",
    "\n",
    "series_data = pd.DataFrame({'PatientSerNum': series_data})\n",
    "series_data = pd.merge(series_data, DATA, on = 'PatientSerNum', how = 'inner')\n",
    "series_data.sort_values(by = ['PatientSerNum', 'ScheduledStartTime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of patient is 35\n"
     ]
    }
   ],
   "source": [
    "series_data_grouped = series_data.groupby('PatientSerNum')\n",
    "maxlen = series_data_grouped.count().AppointmentSerNum.max()\n",
    "print(f'The max length of patient is {maxlen}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### samlpe train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "appt_maxlen = 35\n",
    "feature_len = 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = series_data_grouped.get_group(209)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label sample: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "label_sample = train_sample.Actual_duration.iloc[-1]\n",
    "print(f'label sample: {label_sample}')\n",
    "\n",
    "# 最后一个appointment 为我们需要预测的真实治疗时长所对应的appointment\n",
    "train_sample.Actual_duration.iloc[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 因为存在相隔很远的两次预约，因此，构造特征Interval_scheduled 来度量两次预约之间的距离\n",
    "train_sample['Last_ScheduledStartTime'] = train_sample.ScheduledStartTime.shift(periods = 1,\n",
    "                                                                                fill_value = train_sample.ScheduledStartTime.iloc[0])\n",
    "train_sample['Last_ScheduledStartTime'] = train_sample.Last_ScheduledStartTime.apply(lambda x: str_to_Datetime(x))\n",
    "train_sample['ScheduledStartTime'] = train_sample.ScheduledStartTime.apply(lambda x: str_to_Datetime(x))\n",
    "train_sample['Interval_scheduled'] = train_sample.apply(lambda x: \n",
    "                                                                  (x.ScheduledStartTime - x.Last_ScheduledStartTime).days, \n",
    "                                                                  axis = 1)\n",
    "\n",
    "train_num = train_sample[feature_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cate = pd.DataFrame({})\n",
    "\n",
    "encode_cate['Sex'] = train_sample['Sex'].apply(lambda x: sum(label_encoder_Sex.transform(np.array(x).reshape(-1,1))))\n",
    "\n",
    "encode_cate['dxt_AliasName'] = train_sample['dxt_AliasName'].apply(lambda x: sum(label_encoder_dxt_AliasName.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.vstack(encode_cate.dxt_AliasName.tolist())\n",
    "\n",
    "encode_cate['AliasSerNum'] = train_sample['AliasSerNum'].apply(lambda x: sum(label_encoder_AliasSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.AliasSerNum.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['month'] = train_sample['month'].apply(lambda x: sum(label_encoder_month.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.month.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['week'] = train_sample['week'].apply(lambda x: sum(label_encoder_week.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.week.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['hour'] = train_sample['hour'].apply(lambda x: sum(label_encoder_hour.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.hour.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['DoctorSerNum'] = train_sample['DoctorSerNum'].apply(lambda x: sum(label_encoder_DoctorSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.DoctorSerNum.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['TreatmentOrientation'] = train_sample['TreatmentOrientation'].apply(lambda x: sum(label_encoder_TreatmentOrientation.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.TreatmentOrientation.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['FractionNumber'] = train_sample['FractionNumber'].apply(lambda x: sum(label_encoder_FractionNumber.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.FractionNumber.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['UserName'] = train_sample['UserName'].apply(lambda x: sum(label_encoder_UserName.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.UserName.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['CourseId'] = train_sample['CourseId'].apply(lambda x: sum(label_encoder_CourseId.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.CourseId.tolist()))\n",
    ")\n",
    "\n",
    "encode_cate['ResourceSerNum'] = train_sample['ResourceSerNum'].apply(lambda x: sum(label_encoder_ResourceSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "train_x = np.hstack(\n",
    "    (train_x, np.vstack(encode_cate.ResourceSerNum.tolist()))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.hstack((train_x, train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 438)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((maxlen-encode_cate.shape[0], feature_len))\n",
    "train_x = np.vstack((zeros, train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 438)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0514 21:04:36.289557 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=(None, 35,..., dropout=0.1, recurrent_dropout=0.5, return_sequences=True, units=128)`\n",
      "  import sys\n",
      "W0514 21:04:36.359532 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0514 21:04:36.373686 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0514 21:04:36.523932 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0514 21:04:36.537894 17012 deprecation.py:506] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(dropout=0.1, recurrent_dropout=0.5, units=32)`\n",
      "  del sys.path[0]\n",
      "W0514 21:04:37.507303 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 35, 128)           290304    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 310,945\n",
      "Trainable params: 310,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sequence = Sequential()\n",
    "model_sequence.add(layers.LSTM(\n",
    "        batch_input_shape = (None , appt_maxlen, feature_len),\n",
    "        output_dim = 128,\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.5,\n",
    "        return_sequences=True,\n",
    "        ))\n",
    "\n",
    "model_sequence.add(layers.LSTM(\n",
    "        output_dim = 32,\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.5,\n",
    "        ))\n",
    "# stateful = True 本次batch的参数返回到下一次的训练中\n",
    "\n",
    "model_sequence.add(layers.Dense(1))\n",
    "\n",
    "model_sequence.compile(\n",
    "        optimizer = 'rmsprop',\n",
    "        loss = 'mae'\n",
    "        )\n",
    "\n",
    "model_sequence.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_ = train_x.copy()\n",
    "train_x_ = np.array([train_x_, train_x_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 35, 438)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0514 21:08:44.609842 17012 deprecation.py:323] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0514 21:08:46.732163 17012 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2/2 [==============================] - 2s 1s/step - loss: 19.0296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a88a52c780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sequence.fit(train_x_, [label_sample, label_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cate = hstack((a,b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
       "       [6, 7, 8, 6, 7, 8, 6, 7, 8]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0, 1, 2],\n",
    "             [3, 4, 5],\n",
    "             [6, 7, 8]])\n",
    "\n",
    "b = np.array([[0, 1, 2],\n",
    "             [3, 4, 5],\n",
    "             [6, 7, 8]])\n",
    "\n",
    "c = np.array([[0, 1, 2],\n",
    "             [3, 4, 5],\n",
    "             [6, 7, 8]])\n",
    "\n",
    "np.hstack((a,b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['PatientSerNum', 'AppointmentSerNum',  \n",
    "#        'ScheduledStartTime', 'ScheduledEndTime', \n",
    "#        'ActualStartDate', 'ActualEndDate',\n",
    "#        'CourseSerNum', 'PlanSerNum', 'RadiationSerNum'\n",
    "\n",
    "feature_num = ['Scheduled_duration', 'Actual_duration', 'Actual_duration',\n",
    "               'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "               'MU_total', 'MUCoeff_total']\n",
    "\n",
    "# RadiationId\n",
    "feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum', \n",
    "                'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                'TreatmentOrientation', 'FractionNumber',\n",
    "                'UserName', 'CourseId', 'ResourceSerNum']\n",
    "\n",
    "# 因为数据缺失，所以添加新特征，表示是否是连续的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cate_ = series_data[feature_cate]\n",
    "data_num_ = series_data[feature_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cate = data_cate_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dxt_AliasName</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AliasSerNum</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>DoctorSerNum</th>\n",
       "      <th>TreatmentOrientation</th>\n",
       "      <th>FractionNumber</th>\n",
       "      <th>UserName</th>\n",
       "      <th>CourseId</th>\n",
       "      <th>ResourceSerNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>[GU except prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>24</td>\n",
       "      <td>[poon]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>[GU except prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>25</td>\n",
       "      <td>[poon]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>[GU except prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Basdeo Reeta]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Stachura Jacob]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>[GU except prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Rabanal Javier]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>3</td>\n",
       "      <td>[Lin Michael]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>[GU except prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>3</td>\n",
       "      <td>[Langlais Marianne]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[nowac sydnee]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Stachura Jacob]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>6</td>\n",
       "      <td>[Stachura Jacob]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[Stachura Jacob]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>8</td>\n",
       "      <td>[Lin Michael]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Mistry Jayesha]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>10</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>11</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>12</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>13</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>14</td>\n",
       "      <td>[Chen Shi Lei]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>272.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>15</td>\n",
       "      <td>[poon]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[31]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Li]</td>\n",
       "      <td>[C3]</td>\n",
       "      <td>[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[Seevaratnam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Seevaratnam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>3</td>\n",
       "      <td>[Seevaratnam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[Lieu]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[Rabanal Javier]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>6</td>\n",
       "      <td>[Basdeo Reeta]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>7</td>\n",
       "      <td>[Seevaratnam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>8</td>\n",
       "      <td>[Rabanal Javier]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>[Resp]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>9</td>\n",
       "      <td>[Li]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[esirois]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>6</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[kcrawley]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>7</td>\n",
       "      <td>[rislam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>8</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>3</td>\n",
       "      <td>[adicorpo]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[31]</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5246.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[rbasdeo]</td>\n",
       "      <td>[C6]</td>\n",
       "      <td>[177]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[jstachura]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>9</td>\n",
       "      <td>[sillick]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[jstachura]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>10</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[vcaissie]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>11</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4561.0</td>\n",
       "      <td>[HFS, FFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[mpeuckert]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>12</td>\n",
       "      <td>[vmarsillo]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>13</td>\n",
       "      <td>[rislam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>14</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>15</td>\n",
       "      <td>[rkarant]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>16</td>\n",
       "      <td>[vmarsillo]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>17</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>18</td>\n",
       "      <td>[rislam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[Prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>19</td>\n",
       "      <td>[bblundel]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[Prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[31]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[jbattista]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>[HN]</td>\n",
       "      <td>Female</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>262.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>20</td>\n",
       "      <td>[rislam]</td>\n",
       "      <td>[C2]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[Prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[abelli]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[Prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>2</td>\n",
       "      <td>[jbattista]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[Prostate]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>3</td>\n",
       "      <td>[jbattista]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>4</td>\n",
       "      <td>[amahbub]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[METS]</td>\n",
       "      <td>Male</td>\n",
       "      <td>[23]</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>[HFS]</td>\n",
       "      <td>5</td>\n",
       "      <td>[svilleneuve]</td>\n",
       "      <td>[C1]</td>\n",
       "      <td>[175]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dxt_AliasName     Sex AliasSerNum  month  week  hour  \\\n",
       "470  [GU except prostate]    Male        [23]      1     1     9   \n",
       "471  [GU except prostate]    Male        [23]      1     2     9   \n",
       "169                [METS]    Male        [31]      1     2    14   \n",
       "473  [GU except prostate]    Male        [31]      1     3     9   \n",
       "170                [METS]    Male        [23]      1     3    14   \n",
       "472  [GU except prostate]    Male        [23]      1     4     9   \n",
       "167                [METS]    Male        [23]      1     4    13   \n",
       "474  [GU except prostate]    Male        [23]      1     5     9   \n",
       "171                [METS]    Male        [23]      1     5    13   \n",
       "173                [METS]    Male        [23]      1     1    13   \n",
       "174                [METS]    Male        [23]      1     2    13   \n",
       "172                [METS]    Male        [23]      1     3    14   \n",
       "175                [METS]    Male        [23]      1     4    16   \n",
       "168                [METS]    Male        [23]      1     5    14   \n",
       "176                [METS]    Male        [23]      1     1    13   \n",
       "177                [METS]    Male        [23]      1     2    13   \n",
       "178                [METS]    Male        [23]      1     3    13   \n",
       "179                [METS]    Male        [23]      1     4    13   \n",
       "180                [METS]    Male        [23]      1     5    16   \n",
       "181                [METS]    Male        [23]      1     1    14   \n",
       "276                [METS]  Female        [31]      1     2    12   \n",
       "289                [Resp]    Male        [31]      2     3    12   \n",
       "290                [Resp]    Male        [23]      2     4    18   \n",
       "291                [Resp]    Male        [23]      2     5    17   \n",
       "292                [Resp]    Male        [23]      2     1    16   \n",
       "293                [Resp]    Male        [23]      2     2    18   \n",
       "294                [Resp]    Male        [23]      2     3    18   \n",
       "295                [Resp]    Male        [23]      2     4    18   \n",
       "296                [Resp]    Male        [23]      2     5    18   \n",
       "297                [Resp]    Male        [23]      3     1    18   \n",
       "..                    ...     ...         ...    ...   ...   ...   \n",
       "258                [METS]    Male        [31]      6     2    15   \n",
       "454                  [HN]  Female        [23]      6     2    16   \n",
       "255                [METS]    Male        [23]      6     3    15   \n",
       "455                  [HN]  Female        [23]      6     3    17   \n",
       "456                  [HN]  Female        [23]      6     4    16   \n",
       "260                [METS]    Male        [31]      6     4    17   \n",
       "3                  [METS]  Female        [31]      6     5    12   \n",
       "256                [METS]    Male        [23]      6     5    13   \n",
       "457                  [HN]  Female        [23]      6     5    16   \n",
       "259                [METS]    Male        [23]      6     1    13   \n",
       "458                  [HN]  Female        [23]      6     1    16   \n",
       "261                [METS]    Male        [23]      6     2    14   \n",
       "459                  [HN]  Female        [23]      6     2    16   \n",
       "257                [METS]    Male        [23]      6     3    15   \n",
       "460                  [HN]  Female        [23]      6     3    16   \n",
       "461                  [HN]  Female        [23]      6     4    15   \n",
       "462                  [HN]  Female        [23]      6     5    17   \n",
       "463                  [HN]  Female        [23]      6     2    15   \n",
       "464                  [HN]  Female        [23]      6     3    16   \n",
       "465                  [HN]  Female        [23]      6     4    16   \n",
       "466                  [HN]  Female        [23]      6     5    15   \n",
       "64             [Prostate]    Male        [31]      7     2    16   \n",
       "467                  [HN]  Female        [23]      7     2    17   \n",
       "63             [Prostate]    Male        [31]      7     3    14   \n",
       "468                  [HN]  Female        [23]      7     3    15   \n",
       "58             [Prostate]    Male        [23]      7     4    15   \n",
       "59             [Prostate]    Male        [23]      7     5    13   \n",
       "60             [Prostate]    Male        [23]      7     1    13   \n",
       "61                 [METS]    Male        [23]      7     3    13   \n",
       "62                 [METS]    Male        [23]      7     5    13   \n",
       "\n",
       "     DoctorSerNum TreatmentOrientation  FractionNumber             UserName  \\\n",
       "470        5246.0                [HFS]              24               [poon]   \n",
       "471        5246.0                [HFS]              25               [poon]   \n",
       "169         272.0                [HFS]               1       [Chen Shi Lei]   \n",
       "473        5246.0                [HFS]               1       [Basdeo Reeta]   \n",
       "170         272.0                [HFS]               2     [Stachura Jacob]   \n",
       "472        5246.0                [HFS]               2     [Rabanal Javier]   \n",
       "167         272.0                [HFS]               3        [Lin Michael]   \n",
       "474        5246.0                [HFS]               3  [Langlais Marianne]   \n",
       "171         272.0                [HFS]               4       [nowac sydnee]   \n",
       "173         272.0                [HFS]               5     [Stachura Jacob]   \n",
       "174         272.0                [HFS]               6     [Stachura Jacob]   \n",
       "172         272.0                [HFS]               4     [Stachura Jacob]   \n",
       "175         272.0                [HFS]               8        [Lin Michael]   \n",
       "168         272.0                [HFS]               5     [Mistry Jayesha]   \n",
       "176         272.0                [HFS]              10       [Chen Shi Lei]   \n",
       "177         272.0                [HFS]              11       [Chen Shi Lei]   \n",
       "178         272.0                [HFS]              12       [Chen Shi Lei]   \n",
       "179         272.0                [HFS]              13       [Chen Shi Lei]   \n",
       "180         272.0                [HFS]              14       [Chen Shi Lei]   \n",
       "181         272.0                [HFS]              15               [poon]   \n",
       "276        1109.0                [HFS]               1                 [Li]   \n",
       "289        1102.0                [HFS]               1        [Seevaratnam]   \n",
       "290        1102.0                [HFS]               2        [Seevaratnam]   \n",
       "291        1102.0                [HFS]               3        [Seevaratnam]   \n",
       "292        1102.0                [HFS]               4               [Lieu]   \n",
       "293        1102.0                [HFS]               5     [Rabanal Javier]   \n",
       "294        1102.0                [HFS]               6       [Basdeo Reeta]   \n",
       "295        1102.0                [HFS]               7        [Seevaratnam]   \n",
       "296        1102.0                [HFS]               8     [Rabanal Javier]   \n",
       "297        1102.0                [HFS]               9                 [Li]   \n",
       "..            ...                  ...             ...                  ...   \n",
       "258        4561.0           [HFS, FFS]               1            [esirois]   \n",
       "454         262.0                [HFS]               6             [abelli]   \n",
       "255        4561.0           [HFS, FFS]               2           [kcrawley]   \n",
       "455         262.0                [HFS]               7             [rislam]   \n",
       "456         262.0                [HFS]               8             [abelli]   \n",
       "260        4561.0           [HFS, FFS]               3           [adicorpo]   \n",
       "3          5246.0                [HFS]               1            [rbasdeo]   \n",
       "256        4561.0           [HFS, FFS]               4          [jstachura]   \n",
       "457         262.0                [HFS]               9            [sillick]   \n",
       "259        4561.0           [HFS, FFS]               5          [jstachura]   \n",
       "458         262.0                [HFS]              10             [abelli]   \n",
       "261        4561.0           [HFS, FFS]               4           [vcaissie]   \n",
       "459         262.0                [HFS]              11             [abelli]   \n",
       "257        4561.0           [HFS, FFS]               5          [mpeuckert]   \n",
       "460         262.0                [HFS]              12          [vmarsillo]   \n",
       "461         262.0                [HFS]              13             [rislam]   \n",
       "462         262.0                [HFS]              14             [abelli]   \n",
       "463         262.0                [HFS]              15            [rkarant]   \n",
       "464         262.0                [HFS]              16          [vmarsillo]   \n",
       "465         262.0                [HFS]              17             [abelli]   \n",
       "466         262.0                [HFS]              18             [rislam]   \n",
       "64         5131.0                [HFS]               1             [abelli]   \n",
       "467         262.0                [HFS]              19           [bblundel]   \n",
       "63         5131.0                [HFS]               1          [jbattista]   \n",
       "468         262.0                [HFS]              20             [rislam]   \n",
       "58         5131.0                [HFS]               2             [abelli]   \n",
       "59         5131.0                [HFS]               2          [jbattista]   \n",
       "60         5131.0                [HFS]               3          [jbattista]   \n",
       "61         5131.0                [HFS]               4            [amahbub]   \n",
       "62         5131.0                [HFS]               5        [svilleneuve]   \n",
       "\n",
       "    CourseId ResourceSerNum  \n",
       "470     [C1]           [95]  \n",
       "471     [C1]           [95]  \n",
       "169     [C1]          [107]  \n",
       "473     [C1]           [95]  \n",
       "170     [C1]          [107]  \n",
       "472     [C1]           [95]  \n",
       "167     [C1]          [107]  \n",
       "474     [C1]           [95]  \n",
       "171     [C1]          [107]  \n",
       "173     [C1]          [107]  \n",
       "174     [C1]          [107]  \n",
       "172     [C1]          [107]  \n",
       "175     [C1]          [107]  \n",
       "168     [C1]          [107]  \n",
       "176     [C1]          [107]  \n",
       "177     [C1]          [107]  \n",
       "178     [C1]          [107]  \n",
       "179     [C1]          [107]  \n",
       "180     [C1]          [107]  \n",
       "181     [C1]          [107]  \n",
       "276     [C3]          [107]  \n",
       "289     [C2]           [96]  \n",
       "290     [C2]           [96]  \n",
       "291     [C2]           [96]  \n",
       "292     [C2]           [96]  \n",
       "293     [C2]           [96]  \n",
       "294     [C2]           [96]  \n",
       "295     [C2]           [96]  \n",
       "296     [C2]           [96]  \n",
       "297     [C2]           [96]  \n",
       "..       ...            ...  \n",
       "258     [C1]          [176]  \n",
       "454     [C2]          [175]  \n",
       "255     [C1]          [176]  \n",
       "455     [C2]          [175]  \n",
       "456     [C2]          [175]  \n",
       "260     [C1]          [176]  \n",
       "3       [C6]          [177]  \n",
       "256     [C1]          [176]  \n",
       "457     [C2]          [175]  \n",
       "259     [C1]          [176]  \n",
       "458     [C2]          [175]  \n",
       "261     [C1]          [176]  \n",
       "459     [C2]          [175]  \n",
       "257     [C1]          [176]  \n",
       "460     [C2]          [175]  \n",
       "461     [C2]          [175]  \n",
       "462     [C2]          [175]  \n",
       "463     [C2]          [175]  \n",
       "464     [C2]          [175]  \n",
       "465     [C2]          [175]  \n",
       "466     [C2]          [175]  \n",
       "64      [C1]          [175]  \n",
       "467     [C2]          [175]  \n",
       "63      [C1]          [175]  \n",
       "468     [C2]          [175]  \n",
       "58      [C1]          [175]  \n",
       "59      [C1]          [175]  \n",
       "60      [C1]          [175]  \n",
       "61      [C1]          [175]  \n",
       "62      [C1]          [175]  \n",
       "\n",
       "[578 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cate['dxt_AliasName'] = data_cate['dxt_AliasName'].apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dxt_AliasName           [GU except prostate]\n",
       "Sex                                     Male\n",
       "AliasSerNum                             [23]\n",
       "month                                      1\n",
       "week                                       1\n",
       "hour                                       9\n",
       "DoctorSerNum                            5246\n",
       "TreatmentOrientation                   [HFS]\n",
       "FractionNumber                            24\n",
       "UserName                              [poon]\n",
       "CourseId                                [C1]\n",
       "ResourceSerNum                          [95]\n",
       "Name: 470, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cate.loc[470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder_dxt_AliasName.transform(np.array(['GU except prostate', 'METS']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_encoder_dxt_AliasName.transform(np.array(['GU except prostate']).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()# sparse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of encode_data is (13254, 13)\n"
     ]
    }
   ],
   "source": [
    "data1 = data_part1.iloc[: 10000]\n",
    "data2 = data_part2.iloc[: 10000]\n",
    "\n",
    "encode_data = pd.merge(data1, data2, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "encode_data.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'FractionNumber'], inplace = True)\n",
    "encode_data = encode_data[feature_cate]\n",
    "print(f'The shape of encode_data is {encode_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_encoded = label_encoder.fit_transform(encode_data.Sex)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n"
     ]
    }
   ],
   "source": [
    "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<13254x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
