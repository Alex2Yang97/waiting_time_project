{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(r'D:\\jupyter files\\waiting_time_project\\my_tools')\n",
    "import tools_for_os.for_df as ml_df\n",
    "import tools_for_os.for_file as ml_fl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\jupyter files\\data_waiting_time_project\\preprocess_data\\patient_duration_LSTM_data\\ has created!\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\\\jupyter files\\\\data_waiting_time_project\\\\preprocess_data\\\\'\n",
    "\n",
    "pat_duration_LSTM_data_path = data_path + 'patient_duration_LSTM_data\\\\'\n",
    "ml_fl.create_folder(pat_duration_LSTM_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data_part1 = pd.read_csv(data_path + 'data_part1.csv', index_col = 0)\n",
    "data_part2 = pd.read_csv(data_path + 'data_part2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把字符串转成datetime\n",
    "def str_to_Datetime(st):\n",
    "    dt = datetime.datetime.strptime(st, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = ['Scheduled_duration', 'Actual_duration',\n",
    "               'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "               'MU_total', 'MUCoeff_total', 'Interval_scheduled']\n",
    "\n",
    "# RadiationId\n",
    "feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "                'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                'TreatmentOrientation', 'FractionNumber',\n",
    "                'UserName', 'CourseId', 'ResourceSerNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为需要进行onehot encoding，所以在拼接数据之前，先进行数据格式的处理\n",
    "for col in feature_cate:\n",
    "    try:\n",
    "        data_part1[col].fillna('Unknown', inplace = True)\n",
    "        data_part1[col] = data_part1[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data_part2[col].fillna('Unknown', inplace = True)\n",
    "        data_part2[col] = data_part2[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for col in feature_num:\n",
    "    try:\n",
    "        data_part1.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data_part2.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# data_num = log1p(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "              n_values=None, sparse=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoder\n",
    "label_encoder_dxt_AliasName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_dxt_AliasName.fit(data_part1.dxt_AliasName.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_Sex = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_Sex.fit(data_part1.Sex.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_AliasSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_AliasSerNum.fit(data_part1.AliasSerNum.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_month = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_month.fit(data_part1.month.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_week = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_week.fit(data_part1.week.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_hour = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_hour.fit(data_part1.hour.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_DoctorSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_DoctorSerNum.fit(data_part1.DoctorSerNum.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_TreatmentOrientation = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_TreatmentOrientation.fit(data_part1.TreatmentOrientation.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_FractionNumber = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_FractionNumber.fit(data_part2.FractionNumber.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_UserName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_UserName.fit(data_part2.UserName.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_CourseId = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_CourseId.fit(data_part2.CourseId.values.reshape(-1, 1))\n",
    "\n",
    "label_encoder_ResourceSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "label_encoder_ResourceSerNum.fit(data_part2.ResourceSerNum.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### categorical feature 不同取值的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_num = ['Scheduled_duration', 'Actual_duration', 'Actual_duration',\n",
    "#                'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "#                'MU_total', 'MUCoeff_total']\n",
    "\n",
    "# # RadiationId\n",
    "# feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "#                 'month', 'week', 'hour', 'DoctorSerNum', \n",
    "#                 'TreatmentOrientation', 'FractionNumber',\n",
    "#                 'UserName', 'CourseId', 'ResourceSerNum']\n",
    "\n",
    "# feature_count1 = pd.DataFrame({})\n",
    "# for col in feature_cate:\n",
    "#     try:\n",
    "#         n = len(data_part1[col].unique())\n",
    "#         feature_count1[col] = [n]\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "# feature_count2 = pd.DataFrame({})\n",
    "# for col in feature_cate:\n",
    "#     try:\n",
    "#         n = len(data_part2[col].unique())\n",
    "#         feature_count2[col] = [n]\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69142 with one appointment\n",
      "251892 with more appointment\n",
      "\n",
      "500 appointment data\n",
      "\n",
      "1000 appointment data\n",
      "\n",
      "1500 appointment data\n",
      "\n",
      "2000 appointment data\n",
      "\n",
      "2500 appointment data\n",
      "\n",
      "3000 appointment data\n",
      "\n",
      "3500 appointment data\n",
      "\n",
      "4000 appointment data\n",
      "\n",
      "4500 appointment data\n",
      "\n",
      "5000 appointment data\n",
      "\n",
      "5500 appointment data\n",
      "\n",
      "6000 appointment data\n",
      "\n",
      "6500 appointment data\n",
      "\n",
      "7000 appointment data\n",
      "\n",
      "7500 appointment data\n",
      "\n",
      "8000 appointment data\n",
      "\n",
      "8500 appointment data\n",
      "\n",
      "9000 appointment data\n",
      "\n",
      "9500 appointment data\n",
      "\n",
      "10000 appointment data\n",
      "\n",
      "10500 appointment data\n",
      "\n",
      "11000 appointment data\n",
      "\n",
      "11500 appointment data\n",
      "\n",
      "12000 appointment data\n",
      "\n",
      "12500 appointment data\n",
      "\n",
      "13000 appointment data\n",
      "\n",
      "13500 appointment data\n",
      "\n",
      "14000 appointment data\n",
      "\n",
      "14500 appointment data\n",
      "\n",
      "15000 appointment data\n",
      "\n",
      "15500 appointment data\n",
      "\n",
      "16000 appointment data\n",
      "\n",
      "16500 appointment data\n",
      "\n",
      "17000 appointment data\n",
      "\n",
      "17500 appointment data\n",
      "\n",
      "18000 appointment data\n",
      "\n",
      "18500 appointment data\n",
      "\n",
      "19000 appointment data\n",
      "\n",
      "19500 appointment data\n",
      "\n",
      "20000 appointment data\n",
      "\n",
      "20500 appointment data\n",
      "\n",
      "21000 appointment data\n",
      "\n",
      "21500 appointment data\n",
      "\n",
      "22000 appointment data\n",
      "\n",
      "22500 appointment data\n",
      "\n",
      "23000 appointment data\n",
      "\n",
      "23500 appointment data\n",
      "\n",
      "24000 appointment data\n",
      "\n",
      "24500 appointment data\n",
      "\n",
      "25000 appointment data\n",
      "\n",
      "25500 appointment data\n",
      "\n",
      "26000 appointment data\n",
      "\n",
      "26500 appointment data\n",
      "\n",
      "27000 appointment data\n",
      "\n",
      "27500 appointment data\n",
      "\n",
      "28000 appointment data\n",
      "\n",
      "28500 appointment data\n",
      "\n",
      "29000 appointment data\n",
      "\n",
      "29500 appointment data\n",
      "\n",
      "30000 appointment data\n",
      "\n",
      "30500 appointment data\n",
      "\n",
      "31000 appointment data\n",
      "\n",
      "31500 appointment data\n",
      "\n",
      "32000 appointment data\n",
      "\n",
      "32500 appointment data\n",
      "\n",
      "33000 appointment data\n",
      "\n",
      "33500 appointment data\n",
      "\n",
      "34000 appointment data\n",
      "\n",
      "34500 appointment data\n",
      "\n",
      "35000 appointment data\n",
      "\n",
      "35500 appointment data\n",
      "\n",
      "36000 appointment data\n",
      "\n",
      "36500 appointment data\n",
      "\n",
      "37000 appointment data\n",
      "\n",
      "37500 appointment data\n",
      "\n",
      "38000 appointment data\n",
      "\n",
      "38500 appointment data\n",
      "\n",
      "39000 appointment data\n",
      "\n",
      "39500 appointment data\n",
      "\n",
      "40000 appointment data\n",
      "\n",
      "40500 appointment data\n",
      "\n",
      "41000 appointment data\n",
      "\n",
      "41500 appointment data\n",
      "\n",
      "42000 appointment data\n",
      "\n",
      "42500 appointment data\n",
      "\n",
      "43000 appointment data\n",
      "\n",
      "43500 appointment data\n",
      "\n",
      "44000 appointment data\n",
      "\n",
      "44500 appointment data\n",
      "\n",
      "45000 appointment data\n",
      "\n",
      "45500 appointment data\n",
      "\n",
      "46000 appointment data\n",
      "\n",
      "46500 appointment data\n",
      "\n",
      "47000 appointment data\n",
      "\n",
      "47500 appointment data\n",
      "\n",
      "48000 appointment data\n",
      "\n",
      "48500 appointment data\n",
      "\n",
      "49000 appointment data\n",
      "\n",
      "49500 appointment data\n",
      "\n",
      "50000 appointment data\n",
      "\n",
      "50500 appointment data\n",
      "\n",
      "51000 appointment data\n",
      "\n",
      "51500 appointment data\n",
      "\n",
      "52000 appointment data\n",
      "\n",
      "52500 appointment data\n",
      "\n",
      "53000 appointment data\n",
      "\n",
      "53500 appointment data\n",
      "\n",
      "54000 appointment data\n",
      "\n",
      "54500 appointment data\n",
      "\n",
      "55000 appointment data\n",
      "\n",
      "55500 appointment data\n",
      "\n",
      "56000 appointment data\n",
      "\n",
      "56500 appointment data\n",
      "\n",
      "57000 appointment data\n",
      "\n",
      "57500 appointment data\n",
      "\n",
      "58000 appointment data\n",
      "\n",
      "58500 appointment data\n",
      "\n",
      "59000 appointment data\n",
      "\n",
      "59500 appointment data\n",
      "\n",
      "60000 appointment data\n",
      "\n",
      "60500 appointment data\n",
      "\n",
      "61000 appointment data\n",
      "\n",
      "61500 appointment data\n",
      "\n",
      "62000 appointment data\n",
      "\n",
      "62500 appointment data\n",
      "\n",
      "63000 appointment data\n",
      "\n",
      "63500 appointment data\n",
      "\n",
      "64000 appointment data\n",
      "\n",
      "64500 appointment data\n",
      "\n",
      "65000 appointment data\n",
      "\n",
      "65500 appointment data\n",
      "\n",
      "66000 appointment data\n",
      "\n",
      "66500 appointment data\n",
      "\n",
      "67000 appointment data\n",
      "\n",
      "67500 appointment data\n",
      "\n",
      "68000 appointment data\n",
      "\n",
      "68500 appointment data\n",
      "\n",
      "69000 appointment data\n",
      "\n",
      "69500 appointment data\n",
      "\n",
      "70000 appointment data\n",
      "\n",
      "70500 appointment data\n",
      "\n",
      "71000 appointment data\n",
      "\n",
      "71500 appointment data\n",
      "\n",
      "72000 appointment data\n",
      "\n",
      "72500 appointment data\n",
      "\n",
      "73000 appointment data\n",
      "\n",
      "73500 appointment data\n",
      "\n",
      "74000 appointment data\n",
      "\n",
      "74500 appointment data\n",
      "\n",
      "75000 appointment data\n",
      "\n",
      "75500 appointment data\n",
      "\n",
      "76000 appointment data\n",
      "\n",
      "76500 appointment data\n",
      "\n",
      "77000 appointment data\n",
      "\n",
      "77500 appointment data\n",
      "\n",
      "78000 appointment data\n",
      "\n",
      "78500 appointment data\n",
      "\n",
      "79000 appointment data\n",
      "\n",
      "79500 appointment data\n",
      "\n",
      "80000 appointment data\n",
      "\n",
      "80500 appointment data\n",
      "\n",
      "81000 appointment data\n",
      "\n",
      "81500 appointment data\n",
      "\n",
      "82000 appointment data\n",
      "\n",
      "82500 appointment data\n",
      "\n",
      "83000 appointment data\n",
      "\n",
      "83500 appointment data\n",
      "\n",
      "84000 appointment data\n",
      "\n",
      "84500 appointment data\n",
      "\n",
      "85000 appointment data\n",
      "\n",
      "85500 appointment data\n",
      "\n",
      "86000 appointment data\n",
      "\n",
      "86500 appointment data\n",
      "\n",
      "87000 appointment data\n",
      "\n",
      "87500 appointment data\n",
      "\n",
      "88000 appointment data\n",
      "\n",
      "88500 appointment data\n",
      "\n",
      "89000 appointment data\n",
      "\n",
      "89500 appointment data\n",
      "\n",
      "90000 appointment data\n",
      "\n",
      "90500 appointment data\n",
      "\n",
      "91000 appointment data\n",
      "\n",
      "91500 appointment data\n",
      "\n",
      "92000 appointment data\n",
      "\n",
      "92500 appointment data\n",
      "\n",
      "93000 appointment data\n",
      "\n",
      "93500 appointment data\n",
      "\n",
      "94000 appointment data\n",
      "\n",
      "94500 appointment data\n",
      "\n",
      "95000 appointment data\n",
      "\n",
      "95500 appointment data\n",
      "\n",
      "96000 appointment data\n",
      "\n",
      "96500 appointment data\n",
      "\n",
      "97000 appointment data\n",
      "\n",
      "97500 appointment data\n",
      "\n",
      "98000 appointment data\n",
      "\n",
      "98500 appointment data\n",
      "\n",
      "99000 appointment data\n",
      "\n",
      "99500 appointment data\n",
      "\n",
      "100000 appointment data\n",
      "\n",
      "100500 appointment data\n",
      "\n",
      "101000 appointment data\n",
      "\n",
      "101500 appointment data\n",
      "\n",
      "102000 appointment data\n",
      "\n",
      "102500 appointment data\n",
      "\n",
      "103000 appointment data\n",
      "\n",
      "103500 appointment data\n",
      "\n",
      "104000 appointment data\n",
      "\n",
      "104500 appointment data\n",
      "\n",
      "105000 appointment data\n",
      "\n",
      "105500 appointment data\n",
      "\n",
      "106000 appointment data\n",
      "\n",
      "106500 appointment data\n",
      "\n",
      "107000 appointment data\n",
      "\n",
      "107500 appointment data\n",
      "\n",
      "108000 appointment data\n",
      "\n",
      "108500 appointment data\n",
      "\n",
      "109000 appointment data\n",
      "\n",
      "109500 appointment data\n",
      "\n",
      "110000 appointment data\n",
      "\n",
      "110500 appointment data\n",
      "\n",
      "111000 appointment data\n",
      "\n",
      "111500 appointment data\n",
      "\n",
      "112000 appointment data\n",
      "\n",
      "112500 appointment data\n",
      "\n",
      "113000 appointment data\n",
      "\n",
      "113500 appointment data\n",
      "\n",
      "114000 appointment data\n",
      "\n",
      "114500 appointment data\n",
      "\n",
      "115000 appointment data\n",
      "\n",
      "115500 appointment data\n",
      "\n",
      "116000 appointment data\n",
      "\n",
      "116500 appointment data\n",
      "\n",
      "117000 appointment data\n",
      "\n",
      "117500 appointment data\n",
      "\n",
      "118000 appointment data\n",
      "\n",
      "118500 appointment data\n",
      "\n",
      "119000 appointment data\n",
      "\n",
      "119500 appointment data\n",
      "\n",
      "120000 appointment data\n",
      "\n",
      "120500 appointment data\n",
      "\n",
      "121000 appointment data\n",
      "\n",
      "121500 appointment data\n",
      "\n",
      "122000 appointment data\n",
      "\n",
      "122500 appointment data\n",
      "\n",
      "123000 appointment data\n",
      "\n",
      "123500 appointment data\n",
      "\n",
      "124000 appointment data\n",
      "\n",
      "124500 appointment data\n",
      "\n",
      "125000 appointment data\n",
      "\n",
      "125500 appointment data\n",
      "\n",
      "126000 appointment data\n",
      "\n",
      "126500 appointment data\n",
      "\n",
      "127000 appointment data\n",
      "\n",
      "127500 appointment data\n",
      "\n",
      "128000 appointment data\n",
      "\n",
      "128500 appointment data\n",
      "\n",
      "129000 appointment data\n",
      "\n",
      "129500 appointment data\n",
      "\n",
      "130000 appointment data\n",
      "\n",
      "130500 appointment data\n",
      "\n",
      "131000 appointment data\n",
      "\n",
      "131500 appointment data\n",
      "\n",
      "132000 appointment data\n",
      "\n",
      "132500 appointment data\n",
      "\n",
      "133000 appointment data\n",
      "\n",
      "133500 appointment data\n",
      "\n",
      "134000 appointment data\n",
      "\n",
      "134500 appointment data\n",
      "\n",
      "135000 appointment data\n",
      "\n",
      "135500 appointment data\n",
      "\n",
      "136000 appointment data\n",
      "\n",
      "136500 appointment data\n",
      "\n",
      "137000 appointment data\n",
      "\n",
      "137500 appointment data\n",
      "\n",
      "138000 appointment data\n",
      "\n",
      "138500 appointment data\n",
      "\n",
      "139000 appointment data\n",
      "\n",
      "139500 appointment data\n",
      "\n",
      "140000 appointment data\n",
      "\n",
      "140500 appointment data\n",
      "\n",
      "141000 appointment data\n",
      "\n",
      "141500 appointment data\n",
      "\n",
      "142000 appointment data\n",
      "\n",
      "142500 appointment data\n",
      "\n",
      "143000 appointment data\n",
      "\n",
      "143500 appointment data\n",
      "\n",
      "144000 appointment data\n",
      "\n",
      "144500 appointment data\n",
      "\n",
      "145000 appointment data\n",
      "\n",
      "145500 appointment data\n",
      "\n",
      "146000 appointment data\n",
      "\n",
      "146500 appointment data\n",
      "\n",
      "147000 appointment data\n",
      "\n",
      "147500 appointment data\n",
      "\n",
      "148000 appointment data\n",
      "\n",
      "148500 appointment data\n",
      "\n",
      "149000 appointment data\n",
      "\n",
      "149500 appointment data\n",
      "\n",
      "150000 appointment data\n",
      "\n",
      "150500 appointment data\n",
      "\n",
      "151000 appointment data\n",
      "\n",
      "151500 appointment data\n",
      "\n",
      "152000 appointment data\n",
      "\n",
      "152500 appointment data\n",
      "\n",
      "153000 appointment data\n",
      "\n",
      "153500 appointment data\n",
      "\n",
      "154000 appointment data\n",
      "\n",
      "154500 appointment data\n",
      "\n",
      "155000 appointment data\n",
      "\n",
      "155500 appointment data\n",
      "\n",
      "156000 appointment data\n",
      "\n",
      "156500 appointment data\n",
      "\n",
      "157000 appointment data\n",
      "\n",
      "157500 appointment data\n",
      "\n",
      "158000 appointment data\n",
      "\n",
      "158500 appointment data\n",
      "\n",
      "159000 appointment data\n",
      "\n",
      "159500 appointment data\n",
      "\n",
      "160000 appointment data\n",
      "\n",
      "160500 appointment data\n",
      "\n",
      "161000 appointment data\n",
      "\n",
      "161500 appointment data\n",
      "\n",
      "162000 appointment data\n",
      "\n",
      "162500 appointment data\n",
      "\n",
      "163000 appointment data\n",
      "\n",
      "163500 appointment data\n",
      "\n",
      "164000 appointment data\n",
      "\n",
      "164500 appointment data\n",
      "\n",
      "165000 appointment data\n",
      "\n",
      "165500 appointment data\n",
      "\n",
      "166000 appointment data\n",
      "\n",
      "166500 appointment data\n",
      "\n",
      "167000 appointment data\n",
      "\n",
      "167500 appointment data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "168000 appointment data\n",
      "\n",
      "168500 appointment data\n",
      "\n",
      "169000 appointment data\n",
      "\n",
      "169500 appointment data\n",
      "\n",
      "170000 appointment data\n",
      "\n",
      "170500 appointment data\n",
      "\n",
      "171000 appointment data\n",
      "\n",
      "171500 appointment data\n",
      "\n",
      "172000 appointment data\n",
      "\n",
      "172500 appointment data\n",
      "\n",
      "173000 appointment data\n",
      "\n",
      "173500 appointment data\n",
      "\n",
      "174000 appointment data\n",
      "\n",
      "174500 appointment data\n",
      "\n",
      "175000 appointment data\n",
      "\n",
      "175500 appointment data\n",
      "\n",
      "176000 appointment data\n",
      "\n",
      "176500 appointment data\n",
      "\n",
      "177000 appointment data\n",
      "\n",
      "177500 appointment data\n",
      "\n",
      "178000 appointment data\n",
      "\n",
      "178500 appointment data\n",
      "\n",
      "179000 appointment data\n",
      "\n",
      "179500 appointment data\n",
      "\n",
      "180000 appointment data\n",
      "\n",
      "180500 appointment data\n",
      "\n",
      "181000 appointment data\n",
      "\n",
      "181500 appointment data\n",
      "\n",
      "182000 appointment data\n",
      "\n",
      "182500 appointment data\n",
      "\n",
      "183000 appointment data\n",
      "\n",
      "183500 appointment data\n",
      "\n",
      "184000 appointment data\n",
      "\n",
      "184500 appointment data\n",
      "\n",
      "185000 appointment data\n",
      "\n",
      "185500 appointment data\n",
      "\n",
      "186000 appointment data\n",
      "\n",
      "186500 appointment data\n",
      "\n",
      "187000 appointment data\n",
      "\n",
      "187500 appointment data\n",
      "\n",
      "188000 appointment data\n",
      "\n",
      "188500 appointment data\n",
      "\n",
      "189000 appointment data\n",
      "\n",
      "189500 appointment data\n",
      "\n",
      "190000 appointment data\n",
      "\n",
      "190500 appointment data\n",
      "\n",
      "191000 appointment data\n",
      "\n",
      "191500 appointment data\n",
      "\n",
      "192000 appointment data\n",
      "\n",
      "192500 appointment data\n",
      "\n",
      "193000 appointment data\n",
      "\n",
      "193500 appointment data\n",
      "\n",
      "194000 appointment data\n",
      "\n",
      "194500 appointment data\n",
      "\n",
      "195000 appointment data\n",
      "\n",
      "195500 appointment data\n",
      "\n",
      "196000 appointment data\n",
      "\n",
      "196500 appointment data\n",
      "\n",
      "197000 appointment data\n",
      "\n",
      "197500 appointment data\n",
      "\n",
      "198000 appointment data\n",
      "\n",
      "198500 appointment data\n",
      "\n",
      "199000 appointment data\n",
      "\n",
      "199500 appointment data\n",
      "\n",
      "200000 appointment data\n",
      "\n",
      "200500 appointment data\n",
      "\n",
      "201000 appointment data\n",
      "\n",
      "201500 appointment data\n",
      "\n",
      "202000 appointment data\n",
      "\n",
      "202500 appointment data\n",
      "\n",
      "203000 appointment data\n",
      "\n",
      "203500 appointment data\n",
      "\n",
      "204000 appointment data\n",
      "\n",
      "204500 appointment data\n",
      "\n",
      "205000 appointment data\n",
      "\n",
      "205500 appointment data\n",
      "\n",
      "206000 appointment data\n",
      "\n",
      "206500 appointment data\n",
      "\n",
      "207000 appointment data\n",
      "\n",
      "207500 appointment data\n",
      "\n",
      "208000 appointment data\n",
      "\n",
      "208500 appointment data\n",
      "\n",
      "209000 appointment data\n",
      "\n",
      "209500 appointment data\n",
      "\n",
      "210000 appointment data\n",
      "\n",
      "210500 appointment data\n",
      "\n",
      "211000 appointment data\n",
      "\n",
      "211500 appointment data\n",
      "\n",
      "212000 appointment data\n",
      "\n",
      "212500 appointment data\n",
      "\n",
      "213000 appointment data\n",
      "\n",
      "213500 appointment data\n",
      "\n",
      "214000 appointment data\n",
      "\n",
      "214500 appointment data\n",
      "\n",
      "215000 appointment data\n",
      "\n",
      "215500 appointment data\n",
      "\n",
      "216000 appointment data\n",
      "\n",
      "216500 appointment data\n",
      "\n",
      "217000 appointment data\n",
      "\n",
      "217500 appointment data\n",
      "\n",
      "218000 appointment data\n",
      "\n",
      "218500 appointment data\n",
      "\n",
      "219000 appointment data\n",
      "\n",
      "219500 appointment data\n",
      "\n",
      "220000 appointment data\n",
      "\n",
      "220500 appointment data\n",
      "\n",
      "221000 appointment data\n",
      "\n",
      "221500 appointment data\n",
      "\n",
      "222000 appointment data\n",
      "\n",
      "222500 appointment data\n",
      "\n",
      "223000 appointment data\n",
      "\n",
      "223500 appointment data\n",
      "\n",
      "224000 appointment data\n",
      "\n",
      "224500 appointment data\n",
      "\n",
      "225000 appointment data\n",
      "\n",
      "225500 appointment data\n",
      "\n",
      "226000 appointment data\n",
      "\n",
      "226500 appointment data\n",
      "\n",
      "227000 appointment data\n",
      "\n",
      "227500 appointment data\n",
      "\n",
      "228000 appointment data\n",
      "\n",
      "228500 appointment data\n",
      "\n",
      "229000 appointment data\n",
      "\n",
      "229500 appointment data\n",
      "\n",
      "230000 appointment data\n",
      "\n",
      "230500 appointment data\n",
      "\n",
      "231000 appointment data\n",
      "\n",
      "231500 appointment data\n",
      "\n",
      "232000 appointment data\n",
      "\n",
      "232500 appointment data\n",
      "\n",
      "233000 appointment data\n",
      "\n",
      "233500 appointment data\n",
      "\n",
      "234000 appointment data\n",
      "\n",
      "234500 appointment data\n",
      "\n",
      "235000 appointment data\n",
      "\n",
      "235500 appointment data\n",
      "\n",
      "236000 appointment data\n",
      "\n",
      "236500 appointment data\n",
      "\n",
      "237000 appointment data\n",
      "\n",
      "237500 appointment data\n",
      "\n",
      "238000 appointment data\n",
      "\n",
      "238500 appointment data\n",
      "\n",
      "239000 appointment data\n",
      "\n",
      "239500 appointment data\n",
      "\n",
      "240000 appointment data\n",
      "\n",
      "240500 appointment data\n",
      "\n",
      "241000 appointment data\n",
      "\n",
      "241500 appointment data\n",
      "\n",
      "242000 appointment data\n",
      "\n",
      "242500 appointment data\n",
      "\n",
      "243000 appointment data\n",
      "\n",
      "243500 appointment data\n",
      "\n",
      "244000 appointment data\n",
      "\n",
      "244500 appointment data\n",
      "\n",
      "245000 appointment data\n",
      "\n",
      "245500 appointment data\n",
      "\n",
      "246000 appointment data\n",
      "\n",
      "246500 appointment data\n",
      "\n",
      "247000 appointment data\n",
      "\n",
      "247500 appointment data\n",
      "\n",
      "248000 appointment data\n",
      "\n",
      "248500 appointment data\n",
      "\n",
      "249000 appointment data\n",
      "\n",
      "249500 appointment data\n",
      "\n",
      "250000 appointment data\n",
      "\n",
      "250500 appointment data\n",
      "\n",
      "251000 appointment data\n",
      "\n",
      "251500 appointment data\n"
     ]
    }
   ],
   "source": [
    "data_part1_grouped = data_part1.groupby('AppointmentSerNum')\n",
    "count_appt = data_part1_grouped.count()\n",
    "appt_one_list = count_appt[count_appt.Sex == 1].index.tolist()\n",
    "appt_more_list = count_appt[count_appt.Sex > 1].index.tolist()\n",
    "\n",
    "print(f'{len(appt_one_list)} with one appointment')\n",
    "print(f'{len(appt_more_list)} with more appointment')\n",
    "\n",
    "\n",
    "# key_list = list(data_part1_grouped.groups.keys())\n",
    "data_part1_new = pd.DataFrame({})\n",
    "for i in range(len(appt_more_list)):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f'\\n{i+1} appointment data')\n",
    "        \n",
    "    sample = data_part1_grouped.get_group(appt_more_list[i])\n",
    "    new_appt = pd.DataFrame({\n",
    "        'PatientSerNum': sample.PatientSerNum.tolist()[0],\n",
    "        'AppointmentSerNum': sample.AppointmentSerNum.tolist()[0],\n",
    "        'Sex': sample.Sex.tolist()[0],\n",
    "        'age': sample.age.tolist()[0],\n",
    "        'DoctorSerNum': sample.DoctorSerNum.tolist()[0],\n",
    "        'month': sample.month.tolist()[0],\n",
    "        'date': sample.date.tolist()[0],\n",
    "        'week': sample.week.tolist()[0],\n",
    "        'hour': sample.hour.tolist()[0],\n",
    "        'Scheduled_duration': sample.Scheduled_duration.tolist()[0],\n",
    "        'Actual_duration': sample.Actual_duration.tolist()[0],\n",
    "        'ScheduledStartTime': sample.ScheduledStartTime.tolist()[0],\n",
    "        'ScheduledEndTime': sample.ScheduledEndTime.tolist()[0],\n",
    "        'ActualStartDate': sample.ActualStartDate.tolist()[0],\n",
    "        'ActualEndDate': sample.ActualEndDate.tolist()[0],\n",
    "        \n",
    "        'dxt_AliasName': [list(set(sample.dxt_AliasName.tolist()))], \n",
    "        'AliasSerNum': [list(set(sample.AliasSerNum.tolist()))], \n",
    "        'CourseSerNum': [list(set(sample.CourseSerNum.tolist()))], \n",
    "        'PlanSerNum': [list(set(sample.PlanSerNum.tolist()))], \n",
    "        'TreatmentOrientation': [list(set(sample.TreatmentOrientation.tolist()))],\n",
    "        \n",
    "    })\n",
    "    \n",
    "    data_part1_new = pd.concat([data_part1_new, new_appt], axis = 0)\n",
    "data_part1_new.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime'], inplace = True)\n",
    "data_part1_new.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 with one treatment\n",
      "142560 with more treatment\n",
      "\n",
      "500 treatment data\n",
      "\n",
      "1000 treatment data\n",
      "\n",
      "1500 treatment data\n",
      "\n",
      "2000 treatment data\n",
      "\n",
      "2500 treatment data\n",
      "\n",
      "3000 treatment data\n",
      "\n",
      "3500 treatment data\n",
      "\n",
      "4000 treatment data\n",
      "\n",
      "4500 treatment data\n",
      "\n",
      "5000 treatment data\n",
      "\n",
      "5500 treatment data\n",
      "\n",
      "6000 treatment data\n",
      "\n",
      "6500 treatment data\n",
      "\n",
      "7000 treatment data\n",
      "\n",
      "7500 treatment data\n",
      "\n",
      "8000 treatment data\n",
      "\n",
      "8500 treatment data\n",
      "\n",
      "9000 treatment data\n",
      "\n",
      "9500 treatment data\n",
      "\n",
      "10000 treatment data\n",
      "\n",
      "10500 treatment data\n",
      "\n",
      "11000 treatment data\n",
      "\n",
      "11500 treatment data\n",
      "\n",
      "12000 treatment data\n",
      "\n",
      "12500 treatment data\n",
      "\n",
      "13000 treatment data\n",
      "\n",
      "13500 treatment data\n",
      "\n",
      "14000 treatment data\n",
      "\n",
      "14500 treatment data\n",
      "\n",
      "15000 treatment data\n",
      "\n",
      "15500 treatment data\n",
      "\n",
      "16000 treatment data\n",
      "\n",
      "16500 treatment data\n",
      "\n",
      "17000 treatment data\n",
      "\n",
      "17500 treatment data\n",
      "\n",
      "18000 treatment data\n",
      "\n",
      "18500 treatment data\n",
      "\n",
      "19000 treatment data\n",
      "\n",
      "19500 treatment data\n",
      "\n",
      "20000 treatment data\n",
      "\n",
      "20500 treatment data\n",
      "\n",
      "21000 treatment data\n",
      "\n",
      "21500 treatment data\n",
      "\n",
      "22000 treatment data\n",
      "\n",
      "22500 treatment data\n",
      "\n",
      "23000 treatment data\n",
      "\n",
      "23500 treatment data\n",
      "\n",
      "24000 treatment data\n",
      "\n",
      "24500 treatment data\n",
      "\n",
      "25000 treatment data\n",
      "\n",
      "25500 treatment data\n",
      "\n",
      "26000 treatment data\n",
      "\n",
      "26500 treatment data\n",
      "\n",
      "27000 treatment data\n",
      "\n",
      "27500 treatment data\n",
      "\n",
      "28000 treatment data\n",
      "\n",
      "28500 treatment data\n",
      "\n",
      "29000 treatment data\n",
      "\n",
      "29500 treatment data\n",
      "\n",
      "30000 treatment data\n",
      "\n",
      "30500 treatment data\n",
      "\n",
      "31000 treatment data\n",
      "\n",
      "31500 treatment data\n",
      "\n",
      "32000 treatment data\n",
      "\n",
      "32500 treatment data\n",
      "\n",
      "33000 treatment data\n",
      "\n",
      "33500 treatment data\n",
      "\n",
      "34000 treatment data\n",
      "\n",
      "34500 treatment data\n",
      "\n",
      "35000 treatment data\n",
      "\n",
      "35500 treatment data\n",
      "\n",
      "36000 treatment data\n",
      "\n",
      "36500 treatment data\n",
      "\n",
      "37000 treatment data\n",
      "\n",
      "37500 treatment data\n",
      "\n",
      "38000 treatment data\n",
      "\n",
      "38500 treatment data\n",
      "\n",
      "39000 treatment data\n",
      "\n",
      "39500 treatment data\n",
      "\n",
      "40000 treatment data\n",
      "\n",
      "40500 treatment data\n",
      "\n",
      "41000 treatment data\n",
      "\n",
      "41500 treatment data\n",
      "\n",
      "42000 treatment data\n",
      "\n",
      "42500 treatment data\n",
      "\n",
      "43000 treatment data\n",
      "\n",
      "43500 treatment data\n",
      "\n",
      "44000 treatment data\n",
      "\n",
      "44500 treatment data\n",
      "\n",
      "45000 treatment data\n",
      "\n",
      "45500 treatment data\n",
      "\n",
      "46000 treatment data\n",
      "\n",
      "46500 treatment data\n",
      "\n",
      "47000 treatment data\n",
      "\n",
      "47500 treatment data\n",
      "\n",
      "48000 treatment data\n",
      "\n",
      "48500 treatment data\n",
      "\n",
      "49000 treatment data\n",
      "\n",
      "49500 treatment data\n",
      "\n",
      "50000 treatment data\n",
      "\n",
      "50500 treatment data\n",
      "\n",
      "51000 treatment data\n",
      "\n",
      "51500 treatment data\n",
      "\n",
      "52000 treatment data\n",
      "\n",
      "52500 treatment data\n",
      "\n",
      "53000 treatment data\n",
      "\n",
      "53500 treatment data\n",
      "\n",
      "54000 treatment data\n",
      "\n",
      "54500 treatment data\n",
      "\n",
      "55000 treatment data\n",
      "\n",
      "55500 treatment data\n",
      "\n",
      "56000 treatment data\n",
      "\n",
      "56500 treatment data\n",
      "\n",
      "57000 treatment data\n",
      "\n",
      "57500 treatment data\n",
      "\n",
      "58000 treatment data\n",
      "\n",
      "58500 treatment data\n",
      "\n",
      "59000 treatment data\n",
      "\n",
      "59500 treatment data\n",
      "\n",
      "60000 treatment data\n",
      "\n",
      "60500 treatment data\n",
      "\n",
      "61000 treatment data\n",
      "\n",
      "61500 treatment data\n",
      "\n",
      "62000 treatment data\n",
      "\n",
      "62500 treatment data\n",
      "\n",
      "63000 treatment data\n",
      "\n",
      "63500 treatment data\n",
      "\n",
      "64000 treatment data\n",
      "\n",
      "64500 treatment data\n",
      "\n",
      "65000 treatment data\n",
      "\n",
      "65500 treatment data\n",
      "\n",
      "66000 treatment data\n",
      "\n",
      "66500 treatment data\n",
      "\n",
      "67000 treatment data\n",
      "\n",
      "67500 treatment data\n",
      "\n",
      "68000 treatment data\n",
      "\n",
      "68500 treatment data\n",
      "\n",
      "69000 treatment data\n",
      "\n",
      "69500 treatment data\n",
      "\n",
      "70000 treatment data\n",
      "\n",
      "70500 treatment data\n",
      "\n",
      "71000 treatment data\n",
      "\n",
      "71500 treatment data\n",
      "\n",
      "72000 treatment data\n",
      "\n",
      "72500 treatment data\n",
      "\n",
      "73000 treatment data\n",
      "\n",
      "73500 treatment data\n",
      "\n",
      "74000 treatment data\n",
      "\n",
      "74500 treatment data\n",
      "\n",
      "75000 treatment data\n",
      "\n",
      "75500 treatment data\n",
      "\n",
      "76000 treatment data\n",
      "\n",
      "76500 treatment data\n",
      "\n",
      "77000 treatment data\n",
      "\n",
      "77500 treatment data\n",
      "\n",
      "78000 treatment data\n",
      "\n",
      "78500 treatment data\n",
      "\n",
      "79000 treatment data\n",
      "\n",
      "79500 treatment data\n",
      "\n",
      "80000 treatment data\n",
      "\n",
      "80500 treatment data\n",
      "\n",
      "81000 treatment data\n",
      "\n",
      "81500 treatment data\n",
      "\n",
      "82000 treatment data\n",
      "\n",
      "82500 treatment data\n",
      "\n",
      "83000 treatment data\n",
      "\n",
      "83500 treatment data\n",
      "\n",
      "84000 treatment data\n",
      "\n",
      "84500 treatment data\n",
      "\n",
      "85000 treatment data\n",
      "\n",
      "85500 treatment data\n",
      "\n",
      "86000 treatment data\n",
      "\n",
      "86500 treatment data\n",
      "\n",
      "87000 treatment data\n",
      "\n",
      "87500 treatment data\n",
      "\n",
      "88000 treatment data\n",
      "\n",
      "88500 treatment data\n",
      "\n",
      "89000 treatment data\n",
      "\n",
      "89500 treatment data\n",
      "\n",
      "90000 treatment data\n",
      "\n",
      "90500 treatment data\n",
      "\n",
      "91000 treatment data\n",
      "\n",
      "91500 treatment data\n",
      "\n",
      "92000 treatment data\n",
      "\n",
      "92500 treatment data\n",
      "\n",
      "93000 treatment data\n",
      "\n",
      "93500 treatment data\n",
      "\n",
      "94000 treatment data\n",
      "\n",
      "94500 treatment data\n",
      "\n",
      "95000 treatment data\n",
      "\n",
      "95500 treatment data\n",
      "\n",
      "96000 treatment data\n",
      "\n",
      "96500 treatment data\n",
      "\n",
      "97000 treatment data\n",
      "\n",
      "97500 treatment data\n",
      "\n",
      "98000 treatment data\n",
      "\n",
      "98500 treatment data\n",
      "\n",
      "99000 treatment data\n",
      "\n",
      "99500 treatment data\n",
      "\n",
      "100000 treatment data\n",
      "\n",
      "100500 treatment data\n",
      "\n",
      "101000 treatment data\n",
      "\n",
      "101500 treatment data\n",
      "\n",
      "102000 treatment data\n",
      "\n",
      "102500 treatment data\n",
      "\n",
      "103000 treatment data\n",
      "\n",
      "103500 treatment data\n",
      "\n",
      "104000 treatment data\n",
      "\n",
      "104500 treatment data\n",
      "\n",
      "105000 treatment data\n",
      "\n",
      "105500 treatment data\n",
      "\n",
      "106000 treatment data\n",
      "\n",
      "106500 treatment data\n",
      "\n",
      "107000 treatment data\n",
      "\n",
      "107500 treatment data\n",
      "\n",
      "108000 treatment data\n",
      "\n",
      "108500 treatment data\n",
      "\n",
      "109000 treatment data\n",
      "\n",
      "109500 treatment data\n",
      "\n",
      "110000 treatment data\n",
      "\n",
      "110500 treatment data\n",
      "\n",
      "111000 treatment data\n",
      "\n",
      "111500 treatment data\n",
      "\n",
      "112000 treatment data\n",
      "\n",
      "112500 treatment data\n",
      "\n",
      "113000 treatment data\n",
      "\n",
      "113500 treatment data\n",
      "\n",
      "114000 treatment data\n",
      "\n",
      "114500 treatment data\n",
      "\n",
      "115000 treatment data\n",
      "\n",
      "115500 treatment data\n",
      "\n",
      "116000 treatment data\n",
      "\n",
      "116500 treatment data\n",
      "\n",
      "117000 treatment data\n",
      "\n",
      "117500 treatment data\n",
      "\n",
      "118000 treatment data\n",
      "\n",
      "118500 treatment data\n",
      "\n",
      "119000 treatment data\n",
      "\n",
      "119500 treatment data\n",
      "\n",
      "120000 treatment data\n",
      "\n",
      "120500 treatment data\n",
      "\n",
      "121000 treatment data\n",
      "\n",
      "121500 treatment data\n",
      "\n",
      "122000 treatment data\n",
      "\n",
      "122500 treatment data\n",
      "\n",
      "123000 treatment data\n",
      "\n",
      "123500 treatment data\n",
      "\n",
      "124000 treatment data\n",
      "\n",
      "124500 treatment data\n",
      "\n",
      "125000 treatment data\n",
      "\n",
      "125500 treatment data\n",
      "\n",
      "126000 treatment data\n",
      "\n",
      "126500 treatment data\n",
      "\n",
      "127000 treatment data\n",
      "\n",
      "127500 treatment data\n",
      "\n",
      "128000 treatment data\n",
      "\n",
      "128500 treatment data\n",
      "\n",
      "129000 treatment data\n",
      "\n",
      "129500 treatment data\n",
      "\n",
      "130000 treatment data\n",
      "\n",
      "130500 treatment data\n",
      "\n",
      "131000 treatment data\n",
      "\n",
      "131500 treatment data\n",
      "\n",
      "132000 treatment data\n",
      "\n",
      "132500 treatment data\n",
      "\n",
      "133000 treatment data\n",
      "\n",
      "133500 treatment data\n",
      "\n",
      "134000 treatment data\n",
      "\n",
      "134500 treatment data\n",
      "\n",
      "135000 treatment data\n",
      "\n",
      "135500 treatment data\n",
      "\n",
      "136000 treatment data\n",
      "\n",
      "136500 treatment data\n",
      "\n",
      "137000 treatment data\n",
      "\n",
      "137500 treatment data\n",
      "\n",
      "138000 treatment data\n",
      "\n",
      "138500 treatment data\n",
      "\n",
      "139000 treatment data\n",
      "\n",
      "139500 treatment data\n",
      "\n",
      "140000 treatment data\n",
      "\n",
      "140500 treatment data\n",
      "\n",
      "141000 treatment data\n",
      "\n",
      "141500 treatment data\n",
      "\n",
      "142000 treatment data\n",
      "\n",
      "142500 treatment data\n"
     ]
    }
   ],
   "source": [
    "data_part2_grouped = data_part2.groupby(['PatientSerNum', 'date'])\n",
    "count_pat_appt = data_part2_grouped.count()\n",
    "treat_one_list = count_pat_appt[count_pat_appt.RadiationHstryAriaSer == 1].index.tolist()\n",
    "treat_more_list = count_pat_appt[count_pat_appt.RadiationHstryAriaSer > 1].index.tolist()\n",
    "\n",
    "print(f'{len(treat_one_list)} with one treatment')\n",
    "print(f'{len(treat_more_list)} with more treatment')\n",
    "\n",
    "\n",
    "# key_list = list(data_part2_grouped.groups.keys())\n",
    "data_part2_new = pd.DataFrame({})\n",
    "for i in range(len(treat_more_list)):\n",
    "    if (i+1) % 500 == 0:\n",
    "        print(f'\\n{i+1} treatment data')\n",
    "        \n",
    "    sample = data_part2_grouped.get_group(treat_more_list[i])\n",
    "    try:\n",
    "        new_treat = pd.DataFrame({\n",
    "            'PatientSerNum': sample.PatientSerNum.tolist()[0],\n",
    "            'FractionNumber': sample.FractionNumber.tolist()[0],\n",
    "            'date': sample.date.tolist()[0],\n",
    "\n",
    "            'UserName': [list(set(sample.UserName.tolist()))], \n",
    "            'RadiationSerNum': [list(set(sample.RadiationSerNum.tolist()))], \n",
    "            'RadiationId': [list(set(sample.RadiationId.tolist()))], \n",
    "            'ResourceSerNum': [list(set(sample.ResourceSerNum.tolist()))], \n",
    "            'CourseId': [list(set(sample.CourseId.tolist()))],\n",
    "\n",
    "            'ImagesTaken_total': sum(sample.ImagesTaken.tolist()),\n",
    "            'MU_total': sum(sample.MU.tolist()),\n",
    "            'MUCoeff_total': sum(sample.MUCoeff.tolist()),\n",
    "            'TreatmentTime_total': sum(sample.TreatmentTime.tolist()),\n",
    "        })\n",
    "        data_part2_new = pd.concat([data_part2_new, new_treat], axis = 0)\n",
    "    except:\n",
    "        print(treat_more_list[i])\n",
    "    \n",
    "    \n",
    "data_part2_new.sort_values(by = ['PatientSerNum', 'date', 'FractionNumber'], inplace = True)\n",
    "data_part2_new.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_part1_new.to_csv(pat_duration_LSTM_data_path + 'data_part1_new.csv')\n",
    "# data_part2_new.to_csv(pat_duration_LSTM_data_path + 'data_part2_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data_part1_new is (251892, 20)\n",
      "The shape of data_part1_new is (142560, 12)\n",
      "The shape of data is (106232, 30)\n"
     ]
    }
   ],
   "source": [
    "data_part1_new.head()\n",
    "print(f'The shape of data_part1_new is {data_part1_new.shape}')\n",
    "print(f'The shape of data_part1_new is {data_part2_new.shape}')\n",
    "\n",
    "DATA = pd.merge(data_part1_new, data_part2_new, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "DATA.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'FractionNumber'], inplace = True)\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series_seq 6236\n",
      "series_one 575\n"
     ]
    }
   ],
   "source": [
    "DATA_grouped = DATA.groupby('PatientSerNum')\n",
    "\n",
    "series_count = DATA_grouped.count()\n",
    "series_seq = series_count[series_count.AppointmentSerNum > 1].index.tolist()\n",
    "series_one = series_count[series_count.AppointmentSerNum == 1].index.tolist()\n",
    "print(f'series_seq {len(series_seq)}')\n",
    "print(f'series_one {len(series_one)}')\n",
    "\n",
    "series_seq = pd.DataFrame({'PatientSerNum': series_seq})\n",
    "series_data = pd.merge(series_seq, DATA, on = 'PatientSerNum', how = 'inner')\n",
    "series_data.sort_values(by = ['PatientSerNum', 'ScheduledStartTime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of patient is 6236\n",
      "The max length of patient is 80\n",
      "The number of input encoded-feature is 438\n"
     ]
    }
   ],
   "source": [
    "series_data_grouped = series_data.groupby('PatientSerNum')\n",
    "pat_list = list(series_data_grouped.groups.keys())\n",
    "APPT_LEN = series_data_grouped.count().AppointmentSerNum.max()\n",
    "FEATURE_LEN = 438\n",
    "print(f'The total number of patient is {len(pat_list)}')\n",
    "print(f'The max length of patient is {APPT_LEN}')\n",
    "print(f'The number of input encoded-feature is {FEATURE_LEN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(train_sample, APPT_LEN, FEATURE_LEN):\n",
    "    \n",
    "    # 样本标签\n",
    "    train_y = np.array([train_sample.Actual_duration.iloc[-1]])\n",
    "\n",
    "    # 最后一个appointment 为我们需要预测的真实治疗时长所对应的appointment，所以需要设置为0\n",
    "    train_sample.Actual_duration.iloc[-1] = 0\n",
    "\n",
    "    # 因为存在相隔很远的两次预约，因此，构造特征Interval_scheduled 来度量两次预约之间的距离\n",
    "    ## 上一次的预期治疗开始时间\n",
    "    train_sample['Last_ScheduledStartTime'] = train_sample.ScheduledStartTime.shift(\n",
    "        periods = 1, fill_value = train_sample.ScheduledStartTime.iloc[0])\n",
    "    ## 需要将时间戳从字符型转为datetime 类型，从而计算时间间隔\n",
    "    train_sample['Last_ScheduledStartTime'] = train_sample.Last_ScheduledStartTime.apply(lambda x: str_to_Datetime(x))\n",
    "    train_sample['ScheduledStartTime'] = train_sample.ScheduledStartTime.apply(lambda x: str_to_Datetime(x))\n",
    "    ## 时间间隔\n",
    "    train_sample['Interval_scheduled'] = train_sample.apply(\n",
    "        lambda x: (x.ScheduledStartTime - x.Last_ScheduledStartTime).days, axis = 1)\n",
    "    \n",
    "    # 对分类变量进行one-hot encoding处理\n",
    "    encode_cate = pd.DataFrame({})\n",
    "    \n",
    "    # 这个地方将Sex 作为序列的一部分，并不是在最后的隐藏层进行合并\n",
    "    encode_cate['Sex'] = train_sample['Sex'].apply(\n",
    "        lambda x: sum(label_encoder_Sex.transform(np.array(x).reshape(-1,1))))\n",
    "\n",
    "    encode_cate['dxt_AliasName'] = train_sample['dxt_AliasName'].apply(\n",
    "        lambda x: sum(label_encoder_dxt_AliasName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.vstack(encode_cate.dxt_AliasName.tolist())\n",
    "\n",
    "    encode_cate['AliasSerNum'] = train_sample['AliasSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_AliasSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.AliasSerNum.tolist())))\n",
    "\n",
    "    encode_cate['month'] = train_sample['month'].apply(\n",
    "        lambda x: sum(label_encoder_month.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.month.tolist())))\n",
    "\n",
    "    encode_cate['week'] = train_sample['week'].apply(\n",
    "        lambda x: sum(label_encoder_week.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.week.tolist())))\n",
    "\n",
    "    encode_cate['hour'] = train_sample['hour'].apply(\n",
    "        lambda x: sum(label_encoder_hour.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.hour.tolist())))\n",
    "\n",
    "    encode_cate['DoctorSerNum'] = train_sample['DoctorSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_DoctorSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.DoctorSerNum.tolist())))\n",
    "\n",
    "    encode_cate['TreatmentOrientation'] = train_sample['TreatmentOrientation'].apply(\n",
    "        lambda x: sum(label_encoder_TreatmentOrientation.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.TreatmentOrientation.tolist())))\n",
    "\n",
    "    encode_cate['FractionNumber'] = train_sample['FractionNumber'].apply(\n",
    "        lambda x: sum(label_encoder_FractionNumber.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.FractionNumber.tolist())))\n",
    "\n",
    "    encode_cate['UserName'] = train_sample['UserName'].apply(\n",
    "        lambda x: sum(label_encoder_UserName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.UserName.tolist())))\n",
    "\n",
    "    encode_cate['CourseId'] = train_sample['CourseId'].apply(\n",
    "        lambda x: sum(label_encoder_CourseId.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.CourseId.tolist())))\n",
    "\n",
    "    encode_cate['ResourceSerNum'] = train_sample['ResourceSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_ResourceSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.ResourceSerNum.tolist())))\n",
    "    \n",
    "    # 将数值变量和非数值变量进行合并\n",
    "    train_num = train_sample[feature_num]\n",
    "    train_x = np.hstack((train_x, train_num))\n",
    "    \n",
    "    # 需要满足序列长度的要求，因此对于短序列进行补零操作\n",
    "    zeros = np.zeros((APPT_LEN - train_x.shape[0], FEATURE_LEN))\n",
    "    train_x = np.vstack((zeros, train_x))\n",
    "    \n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0515 16:53:54.828356 23200 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=(None, 80,..., dropout=0.1, recurrent_dropout=0.5, return_sequences=True, units=128)`\n",
      "  import sys\n",
      "W0515 16:53:54.969973 23200 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0515 16:53:54.993910 23200 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0515 16:53:55.171442 23200 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0515 16:53:55.182406 23200 deprecation.py:506] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "C:\\Users\\WENDY\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(dropout=0.1, recurrent_dropout=0.5, units=32)`\n",
      "  del sys.path[0]\n",
      "W0515 16:53:55.863585 23200 deprecation_wrapper.py:119] From C:\\Users\\WENDY\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 80, 128)           290304    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 310,945\n",
      "Trainable params: 310,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sequence = Sequential()\n",
    "model_sequence.add(layers.LSTM(\n",
    "        batch_input_shape = (None , APPT_LEN, FEATURE_LEN),\n",
    "        output_dim = 128,\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.5,\n",
    "        return_sequences=True,\n",
    "        ))\n",
    "\n",
    "model_sequence.add(layers.LSTM(\n",
    "        output_dim = 32,\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.5,\n",
    "        ))\n",
    "# stateful = True 本次batch的参数返回到下一次的训练中\n",
    "\n",
    "model_sequence.add(layers.Dense(1))\n",
    "\n",
    "model_sequence.compile(\n",
    "        optimizer = 'rmsprop',\n",
    "        loss = 'mae'\n",
    "        )\n",
    "\n",
    "model_sequence.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_train = 40\n",
    "BATCH_test = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "0-40-train [27.79852867126465] ||| 40-45-validation [16.947921752929688]\n",
      "Batch 1\n",
      "45-85-train [18.503265380859375] ||| 85-90-validation [17.30916404724121]\n",
      "Batch 2\n",
      "90-130-train [17.67962646484375] ||| 130-135-validation [10.313223838806152]\n",
      "Batch 3\n",
      "135-175-train [21.097702026367188] ||| 175-180-validation [21.6777400970459]\n",
      "Batch 4\n",
      "180-220-train [16.94692611694336] ||| 220-225-validation [15.307809829711914]\n",
      "Batch 5\n",
      "225-265-train [20.621337890625] ||| 265-270-validation [9.908743858337402]\n",
      "Batch 6\n",
      "270-310-train [16.405019760131836] ||| 310-315-validation [22.659000396728516]\n",
      "Batch 7\n",
      "315-355-train [17.12112045288086] ||| 355-360-validation [5.226141929626465]\n",
      "Batch 8\n",
      "360-400-train [15.261395454406738] ||| 400-405-validation [16.93443489074707]\n",
      "Batch 9\n",
      "405-445-train [16.690845489501953] ||| 445-450-validation [8.161260604858398]\n",
      "Batch 10\n",
      "450-490-train [14.998847961425781] ||| 490-495-validation [8.66822624206543]\n",
      "Batch 11\n",
      "495-535-train [14.400796890258789] ||| 535-540-validation [18.26951789855957]\n",
      "Batch 12\n",
      "540-580-train [15.25951862335205] ||| 580-585-validation [5.142184257507324]\n",
      "Batch 13\n",
      "585-625-train [14.9329252243042] ||| 625-630-validation [16.107372283935547]\n",
      "Batch 14\n",
      "630-670-train [17.19823455810547] ||| 670-675-validation [6.673736572265625]\n",
      "Batch 15\n",
      "675-715-train [12.476923942565918] ||| 715-720-validation [8.699965476989746]\n",
      "Batch 16\n",
      "720-760-train [14.700617790222168] ||| 760-765-validation [6.485640525817871]\n",
      "Batch 17\n",
      "765-805-train [10.577204704284668] ||| 805-810-validation [10.45772933959961]\n",
      "Batch 18\n",
      "810-850-train [12.839062690734863] ||| 850-855-validation [34.29035949707031]\n",
      "Batch 19\n",
      "855-895-train [13.164571762084961] ||| 895-900-validation [12.105684280395508]\n",
      "Batch 20\n",
      "900-940-train [17.110254287719727] ||| 940-945-validation [2.8966622352600098]\n",
      "Batch 21\n",
      "945-985-train [10.37403392791748] ||| 985-990-validation [43.911346435546875]\n",
      "Batch 22\n",
      "990-1030-train [9.379049301147461] ||| 1030-1035-validation [3.7950711250305176]\n",
      "Batch 23\n",
      "1035-1075-train [11.755577087402344] ||| 1075-1080-validation [3.7120566368103027]\n",
      "Batch 24\n",
      "1080-1120-train [10.382070541381836] ||| 1120-1125-validation [6.663763523101807]\n",
      "Batch 25\n",
      "1125-1165-train [10.591455459594727] ||| 1165-1170-validation [14.60142993927002]\n",
      "Batch 26\n",
      "1170-1210-train [11.284327507019043] ||| 1210-1215-validation [8.554771423339844]\n",
      "Batch 27\n",
      "1215-1255-train [13.563522338867188] ||| 1255-1260-validation [5.486476421356201]\n",
      "Batch 28\n",
      "1260-1300-train [11.085283279418945] ||| 1300-1305-validation [11.458864212036133]\n",
      "Batch 29\n",
      "1305-1345-train [19.054811477661133] ||| 1345-1350-validation [16.39028549194336]\n",
      "Batch 30\n",
      "1350-1390-train [8.122513771057129] ||| 1390-1395-validation [8.491575241088867]\n",
      "Batch 31\n",
      "1395-1435-train [9.267779350280762] ||| 1435-1440-validation [2.69871187210083]\n",
      "Batch 32\n",
      "1440-1480-train [9.924497604370117] ||| 1480-1485-validation [4.2537431716918945]\n",
      "Batch 33\n",
      "1485-1525-train [12.306447982788086] ||| 1525-1530-validation [5.207573413848877]\n",
      "Batch 34\n",
      "1530-1570-train [8.746187210083008] ||| 1570-1575-validation [4.159880638122559]\n",
      "Batch 35\n",
      "1575-1615-train [9.895014762878418] ||| 1615-1620-validation [2.1279759407043457]\n",
      "Batch 36\n",
      "1620-1660-train [11.110270500183105] ||| 1660-1665-validation [11.08439826965332]\n",
      "Batch 37\n",
      "1665-1705-train [9.106561660766602] ||| 1705-1710-validation [0.8160595893859863]\n",
      "Batch 38\n",
      "1710-1750-train [9.376875877380371] ||| 1750-1755-validation [0.9927468299865723]\n",
      "Batch 39\n",
      "1755-1795-train [8.570881843566895] ||| 1795-1800-validation [0.027997970581054688]\n",
      "Batch 40\n",
      "1800-1840-train [9.863480567932129] ||| 1840-1845-validation [14.932455062866211]\n",
      "Batch 41\n",
      "1845-1885-train [8.987627983093262] ||| 1885-1890-validation [3.9022274017333984]\n",
      "Batch 42\n",
      "1890-1930-train [8.485291481018066] ||| 1930-1935-validation [12.863061904907227]\n",
      "Batch 43\n",
      "1935-1975-train [10.11771011352539] ||| 1975-1980-validation [0.8388223648071289]\n",
      "Batch 44\n",
      "1980-2020-train [12.168886184692383] ||| 2020-2025-validation [8.79983901977539]\n",
      "Batch 45\n",
      "2025-2065-train [7.426855564117432] ||| 2065-2070-validation [0.7651891708374023]\n",
      "Batch 46\n",
      "2070-2110-train [9.14484977722168] ||| 2110-2115-validation [4.731403350830078]\n",
      "Batch 47\n",
      "2115-2155-train [9.845232963562012] ||| 2155-2160-validation [0.30108165740966797]\n",
      "Batch 48\n",
      "2160-2200-train [9.533344268798828] ||| 2200-2205-validation [9.666341781616211]\n",
      "Batch 49\n",
      "2205-2245-train [8.804722785949707] ||| 2245-2250-validation [10.63215446472168]\n",
      "Batch 50\n",
      "2250-2290-train [13.127336502075195] ||| 2290-2295-validation [38.597923278808594]\n",
      "Batch 51\n",
      "2295-2335-train [8.629423141479492] ||| 2335-2340-validation [2.5620288848876953]\n",
      "Batch 52\n",
      "2340-2380-train [14.916648864746094] ||| 2380-2385-validation [0.4651355743408203]\n",
      "Batch 53\n",
      "2385-2425-train [11.028600692749023] ||| 2425-2430-validation [1.4861278533935547]\n",
      "Batch 54\n",
      "2430-2470-train [10.33331298828125] ||| 2470-2475-validation [35.45267868041992]\n",
      "Batch 55\n",
      "2475-2515-train [9.48738956451416] ||| 2515-2520-validation [3.420682907104492]\n",
      "Batch 56\n",
      "2520-2560-train [11.527990341186523] ||| 2560-2565-validation [4.384430885314941]\n",
      "Batch 57\n",
      "2565-2605-train [10.257421493530273] ||| 2605-2610-validation [28.350154876708984]\n",
      "Batch 58\n",
      "2610-2650-train [10.945989608764648] ||| 2650-2655-validation [0.6787881851196289]\n",
      "Batch 59\n",
      "2655-2695-train [9.630475044250488] ||| 2695-2700-validation [10.286689758300781]\n",
      "Batch 60\n",
      "2700-2740-train [12.300874710083008] ||| 2740-2745-validation [4.252326011657715]\n",
      "Batch 61\n",
      "2745-2785-train [9.900411605834961] ||| 2785-2790-validation [24.21640968322754]\n",
      "Batch 62\n",
      "2790-2830-train [11.314363479614258] ||| 2830-2835-validation [8.18081283569336]\n",
      "Batch 63\n",
      "2835-2875-train [10.96684741973877] ||| 2875-2880-validation [7.147134304046631]\n",
      "Batch 64\n",
      "2880-2920-train [11.427441596984863] ||| 2920-2925-validation [8.11520767211914]\n",
      "Batch 65\n",
      "2925-2965-train [10.962481498718262] ||| 2965-2970-validation [1.081521987915039]\n",
      "Batch 66\n",
      "2970-3010-train [9.984445571899414] ||| 3010-3015-validation [0.05298805236816406]\n",
      "Batch 67\n",
      "3015-3055-train [13.978555679321289] ||| 3055-3060-validation [28.018939971923828]\n",
      "Batch 68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-244ec47ac677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mpat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries_data_grouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mval_x_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAPPT_LEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURE_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mval_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mval_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-930521d87647>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[1;34m(train_sample, APPT_LEN, FEATURE_LEN)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# 最后一个appointment 为我们需要预测的真实治疗时长所对应的appointment，所以需要设置为0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActual_duration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 因为存在相隔很远的两次预约，因此，构造特征Interval_scheduled 来度量两次预约之间的距离\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# check for chained assignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;31m# actually do the set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[1;32m-> 3199\u001b[1;33m                                          force=True)\n\u001b[0m\u001b[0;32m   3200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3201\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(int(len(pat_list)/(BATCH_train + BATCH_test))):\n",
    "    print(f'Batch {i}')\n",
    "    # 构造训练数据\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for tr in range((BATCH_train+BATCH_test)*i,\n",
    "                    (BATCH_train+BATCH_test)*(i+1) - BATCH_test):\n",
    "        pat = pat_list[tr]\n",
    "        train_sample = series_data_grouped.get_group(pat)\n",
    "        train_x_i, train_y_i = generate_sample(train_sample, APPT_LEN, FEATURE_LEN)\n",
    "        train_x.append(train_x_i)\n",
    "        train_y.append(train_y_i)\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    train_result = model_sequence.train_on_batch(train_x, train_y)\n",
    "        \n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    for te in range((BATCH_train+BATCH_test)*(i+1) - BATCH_test,\n",
    "                    (BATCH_train+BATCH_test)*(i+1)):\n",
    "        pat = pat_list[tr]\n",
    "        train_sample = series_data_grouped.get_group(pat)\n",
    "        val_x_i, val_y_i = generate_sample(train_sample, APPT_LEN, FEATURE_LEN)\n",
    "        val_x.append(val_x_i)\n",
    "        val_y.append(val_y_i)\n",
    "    val_x = np.array(val_x)\n",
    "    val_y = np.array(val_y)\n",
    "    # model_sequence.train_on_batch(val_x, val_y)\n",
    "    val_result = model_sequence.evaluate(val_x, val_y, verbose=0) # verbose 显示的时候有进度条\n",
    "    print(f'{tr+1 - BATCH_train}-{tr+1}-train [{train_result}] ||| {te+1 - BATCH_test}-{te+1}-validation [{val_result}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 80, 128)           217728    \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 32)                15456     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 233,217\n",
      "Trainable params: 233,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dropout=0.1,\n",
    "# recurrent_dropout=0.5,\n",
    "\n",
    "model_sequence1 = Sequential()\n",
    "model_sequence1.add(layers.GRU(\n",
    "        batch_input_shape = (None , APPT_LEN, FEATURE_LEN),\n",
    "        output_dim = 128,\n",
    "\n",
    "        return_sequences=True,\n",
    "        ))\n",
    "\n",
    "# dropout=0.1,\n",
    "# recurrent_dropout=0.5,\n",
    "\n",
    "model_sequence1.add(layers.GRU(\n",
    "        output_dim = 32,\n",
    "\n",
    "        ))\n",
    "# stateful = True 本次batch的参数返回到下一次的训练中\n",
    "\n",
    "model_sequence1.add(layers.Dense(1))\n",
    "\n",
    "model_sequence1.compile(\n",
    "        optimizer = 'rmsprop',\n",
    "        loss = 'mae'\n",
    "        )\n",
    "\n",
    "model_sequence1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "0-40-train [29.033550262451172] ||| 40-45-validation [17.26938247680664]\n",
      "Batch 1\n",
      "45-85-train [18.42552375793457] ||| 85-90-validation [15.728889465332031]\n",
      "Batch 2\n",
      "90-130-train [17.172286987304688] ||| 130-135-validation [10.300146102905273]\n",
      "Batch 3\n",
      "135-175-train [20.477676391601562] ||| 175-180-validation [20.931716918945312]\n",
      "Batch 4\n",
      "180-220-train [15.885931015014648] ||| 220-225-validation [14.639741897583008]\n",
      "Batch 5\n",
      "225-265-train [19.633190155029297] ||| 265-270-validation [7.4754228591918945]\n",
      "Batch 6\n",
      "270-310-train [13.881879806518555] ||| 310-315-validation [20.360618591308594]\n",
      "Batch 7\n",
      "315-355-train [14.46210765838623] ||| 355-360-validation [3.0205907821655273]\n",
      "Batch 8\n",
      "360-400-train [12.831311225891113] ||| 400-405-validation [14.861434936523438]\n",
      "Batch 9\n",
      "405-445-train [14.254976272583008] ||| 445-450-validation [5.8323445320129395]\n",
      "Batch 10\n",
      "450-490-train [12.768884658813477] ||| 490-495-validation [6.7624006271362305]\n",
      "Batch 11\n",
      "495-535-train [12.343925476074219] ||| 535-540-validation [16.65709686279297]\n",
      "Batch 12\n",
      "540-580-train [13.27532958984375] ||| 580-585-validation [3.600989580154419]\n",
      "Batch 13\n",
      "585-625-train [13.190481185913086] ||| 625-630-validation [14.562875747680664]\n",
      "Batch 14\n",
      "630-670-train [15.462725639343262] ||| 670-675-validation [5.492772102355957]\n",
      "Batch 15\n",
      "675-715-train [10.875143051147461] ||| 715-720-validation [7.449995517730713]\n",
      "Batch 16\n",
      "720-760-train [13.16185474395752] ||| 760-765-validation [5.439629077911377]\n",
      "Batch 17\n",
      "765-805-train [9.466924667358398] ||| 805-810-validation [9.367010116577148]\n",
      "Batch 18\n",
      "810-850-train [11.547209739685059] ||| 850-855-validation [33.32210159301758]\n",
      "Batch 19\n",
      "855-895-train [12.11719036102295] ||| 895-900-validation [11.279465675354004]\n",
      "Batch 20\n",
      "900-940-train [16.106698989868164] ||| 940-945-validation [3.7650279998779297]\n",
      "Batch 21\n",
      "945-985-train [9.322242736816406] ||| 985-990-validation [43.19862747192383]\n",
      "Batch 22\n",
      "990-1030-train [8.37379264831543] ||| 1030-1035-validation [3.158372402191162]\n",
      "Batch 23\n",
      "1035-1075-train [10.975160598754883] ||| 1075-1080-validation [3.114107608795166]\n",
      "Batch 24\n",
      "1080-1120-train [9.563238143920898] ||| 1120-1125-validation [6.077256679534912]\n",
      "Batch 25\n",
      "1125-1165-train [9.887956619262695] ||| 1165-1170-validation [14.038228988647461]\n",
      "Batch 26\n",
      "1170-1210-train [10.549654006958008] ||| 1210-1215-validation [8.002077102661133]\n",
      "Batch 27\n",
      "1215-1255-train [12.93274211883545] ||| 1255-1260-validation [4.969959259033203]\n",
      "Batch 28\n",
      "1260-1300-train [10.397086143493652] ||| 1300-1305-validation [10.935868263244629]\n",
      "Batch 29\n",
      "1305-1345-train [18.499923706054688] ||| 1345-1350-validation [15.90489673614502]\n",
      "Batch 30\n",
      "1350-1390-train [7.554978847503662] ||| 1390-1395-validation [7.912192344665527]\n",
      "Batch 31\n",
      "1395-1435-train [8.987907409667969] ||| 1435-1440-validation [3.1541738510131836]\n",
      "Batch 32\n",
      "1440-1480-train [9.405927658081055] ||| 1480-1485-validation [3.812253952026367]\n",
      "Batch 33\n",
      "1485-1525-train [11.791290283203125] ||| 1525-1530-validation [4.779034614562988]\n",
      "Batch 34\n",
      "1530-1570-train [8.295125961303711] ||| 1570-1575-validation [3.750781297683716]\n",
      "Batch 35\n",
      "1575-1615-train [9.425666809082031] ||| 1615-1620-validation [1.7165288925170898]\n",
      "Batch 36\n",
      "1620-1660-train [10.703584671020508] ||| 1660-1665-validation [10.684527397155762]\n",
      "Batch 37\n",
      "1665-1705-train [8.683987617492676] ||| 1705-1710-validation [1.1592350006103516]\n",
      "Batch 38\n",
      "1710-1750-train [9.088254928588867] ||| 1750-1755-validation [1.3807296752929688]\n",
      "Batch 39\n",
      "1755-1795-train [8.167673110961914] ||| 1795-1800-validation [0.41464900970458984]\n",
      "Batch 40\n",
      "1800-1840-train [9.455282211303711] ||| 1840-1845-validation [14.549215316772461]\n",
      "Batch 41\n",
      "1845-1885-train [8.640848159790039] ||| 1885-1890-validation [3.517909288406372]\n",
      "Batch 42\n",
      "1890-1930-train [8.108800888061523] ||| 1930-1935-validation [12.482658386230469]\n",
      "Batch 43\n",
      "1935-1975-train [9.83915901184082] ||| 1975-1980-validation [0.45415210723876953]\n",
      "Batch 44\n",
      "1980-2020-train [11.786384582519531] ||| 2020-2025-validation [8.418599128723145]\n",
      "Batch 45\n",
      "2025-2065-train [7.060329437255859] ||| 2065-2070-validation [0.3853330612182617]\n",
      "Batch 46\n",
      "2070-2110-train [8.810149192810059] ||| 2110-2115-validation [4.351316452026367]\n",
      "Batch 47\n",
      "2115-2155-train [9.50554370880127] ||| 2155-2160-validation [0.6827058792114258]\n",
      "Batch 48\n",
      "2160-2200-train [9.206945419311523] ||| 2200-2205-validation [9.284711837768555]\n",
      "Batch 49\n",
      "2205-2245-train [8.41862964630127] ||| 2245-2250-validation [10.249488830566406]\n",
      "Batch 50\n",
      "2250-2290-train [12.751091003417969] ||| 2290-2295-validation [38.21573257446289]\n",
      "Batch 51\n",
      "2295-2335-train [8.283462524414062] ||| 2335-2340-validation [2.177316665649414]\n",
      "Batch 52\n",
      "2340-2380-train [14.52015209197998] ||| 2380-2385-validation [0.7885618209838867]\n",
      "Batch 53\n",
      "2385-2425-train [10.61923885345459] ||| 2425-2430-validation [1.1009511947631836]\n",
      "Batch 54\n",
      "2430-2470-train [9.967939376831055] ||| 2470-2475-validation [35.06837463378906]\n",
      "Batch 55\n",
      "2475-2515-train [9.154203414916992] ||| 2515-2520-validation [3.0340394973754883]\n",
      "Batch 56\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c7e44abeab68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtrain_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries_data_grouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_x_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAPPT_LEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURE_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-930521d87647>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[1;34m(train_sample, APPT_LEN, FEATURE_LEN)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m## 时间间隔\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     train_sample['Interval_scheduled'] = train_sample.apply(\n\u001b[1;32m---> 18\u001b[1;33m         lambda x: (x.ScheduledStartTime - x.Last_ScheduledStartTime).days, axis = 1)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 对分类变量进行one-hot encoding处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3450\u001b[0m         \u001b[1;31m# value exception to occur first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3452\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3454\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "for i in range(int(len(pat_list)/(BATCH_train + BATCH_test))):\n",
    "    print(f'Batch {i}')\n",
    "    # 构造训练数据\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for tr in range((BATCH_train+BATCH_test)*i,\n",
    "                    (BATCH_train+BATCH_test)*(i+1) - BATCH_test):\n",
    "        pat = pat_list[tr]\n",
    "        train_sample = series_data_grouped.get_group(pat)\n",
    "        train_x_i, train_y_i = generate_sample(train_sample, APPT_LEN, FEATURE_LEN)\n",
    "        train_x.append(train_x_i)\n",
    "        train_y.append(train_y_i)\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    train_result = model_sequence1.train_on_batch(train_x, train_y)\n",
    "        \n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    for te in range((BATCH_train+BATCH_test)*(i+1) - BATCH_test,\n",
    "                    (BATCH_train+BATCH_test)*(i+1)):\n",
    "        pat = pat_list[tr]\n",
    "        train_sample = series_data_grouped.get_group(pat)\n",
    "        val_x_i, val_y_i = generate_sample(train_sample, APPT_LEN, FEATURE_LEN)\n",
    "        val_x.append(val_x_i)\n",
    "        val_y.append(val_y_i)\n",
    "    val_x = np.array(val_x)\n",
    "    val_y = np.array(val_y)\n",
    "    # model_sequence.train_on_batch(val_x, val_y)\n",
    "    val_result = model_sequence1.evaluate(val_x, val_y, verbose=0) # verbose 显示的时候有进度条\n",
    "    print(f'{tr+1 - BATCH_train}-{tr+1}-train [{train_result}] ||| {te+1 - BATCH_test}-{te+1}-validation [{val_result}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
