{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\10768\\personal files\\waiting_time\\waiting_time_project')\n",
    "\n",
    "from utils.logger import logger\n",
    "from data_process import get_apptointment_info, get_treat_info, fill_nan, get_list\n",
    "from wtp.duration.predict_lgb_model import FEATURE_NUM, FEATURE_CATE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WAITING TIME: 2020-08-18 11:04:27 [INFO] Get information about appointment!\n",
      "WAITING TIME: 2020-08-18 11:04:27 [DEBUG] Get table of appointment!\n",
      "WAITING TIME: 2020-08-18 11:05:10 [DEBUG] Get table of patient!\n",
      "WAITING TIME: 2020-08-18 11:05:11 [DEBUG] Merge appointment and patient!\n",
      "WAITING TIME: 2020-08-18 11:05:12 [DEBUG] Get table of patientdoctor!\n",
      "WAITING TIME: 2020-08-18 11:05:14 [DEBUG] Merge patientdoctor!\n",
      "WAITING TIME: 2020-08-18 11:05:14 [DEBUG] Get table of diagnosis!\n",
      "WAITING TIME: 2020-08-18 11:05:15 [DEBUG] Get table of diagnosis!\n",
      "WAITING TIME: 2020-08-18 11:05:15 [DEBUG] Merge diagnosis and diagnosistranslation!\n",
      "WAITING TIME: 2020-08-18 11:05:16 [DEBUG] Get table of course!\n",
      "WAITING TIME: 2020-08-18 11:05:17 [DEBUG] Get table of plan!\n",
      "WAITING TIME: 2020-08-18 11:05:21 [DEBUG] Merge plan and course!\n",
      "WAITING TIME: 2020-08-18 11:05:22 [DEBUG] Merge plan_course and appointment!\n",
      "WAITING TIME: 2020-08-18 11:05:22 [DEBUG] Drop columns with same values!\n",
      "WAITING TIME: 2020-08-18 11:05:26 [DEBUG] Process appointment data!\n",
      "WAITING TIME: 2020-08-18 11:07:57 [INFO] Get information about treatment!\n",
      "WAITING TIME: 2020-08-18 11:07:57 [DEBUG] Get table of radiation!\n",
      "WAITING TIME: 2020-08-18 11:08:12 [DEBUG] Get table of radiationhstry!\n",
      "WAITING TIME: 2020-08-18 11:09:27 [DEBUG] Merge radiation and radiationhstry!\n",
      "WAITING TIME: 2020-08-18 11:09:27 [DEBUG] Merge plan!\n",
      "WAITING TIME: 2020-08-18 11:09:32 [DEBUG] Get table of radiation!\n",
      "WAITING TIME: 2020-08-18 11:09:34 [DEBUG] Get table of radiation!\n",
      "WAITING TIME: 2020-08-18 11:09:34 [DEBUG] Merge course and patient\n",
      "WAITING TIME: 2020-08-18 11:09:34 [DEBUG] Merge radiation and radiation!\n",
      "WAITING TIME: 2020-08-18 11:09:35 [DEBUG] Drop columns with same values!\n",
      "WAITING TIME: 2020-08-18 11:09:36 [DEBUG] Process treatment data!\n"
     ]
    }
   ],
   "source": [
    "processed_appointment_data_ = get_apptointment_info()\n",
    "processed_treatment_data_ = get_treat_info()\n",
    "\n",
    "processed_appointment_data = processed_appointment_data_.copy()\n",
    "processed_treatment_data = processed_treatment_data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.merge(processed_appointment_data, processed_treatment_data, on=['PatientSerNum', 'date'], how='inner')\n",
    "processed_data = processed_data.sort_values(\n",
    "    by=['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'FractionNumber']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(processed_data[FEATURE_NUM])\n",
    "processed_data.loc[:, FEATURE_NUM] = imp_mean.transform(processed_data[FEATURE_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_features = processed_data[FEATURE_CATE].select_dtypes(include=['category', 'object']).columns\n",
    "cate_features_number = [i for i in FEATURE_CATE if i not in cate_features]\n",
    "\n",
    "processed_data.loc[:, cate_features] = processed_data.loc[:, cate_features].fillna('NULL').reset_index(drop=True)\n",
    "processed_data.loc[:, cate_features_number] = processed_data.loc[:, cate_features_number].fillna(0).reset_index(drop=True)\n",
    "\n",
    "# imp_mean = SimpleImputer(strategy='most_frequent')\n",
    "# imp_mean.fit(processed_data[FEATURE_CATE])\n",
    "# processed_data.loc[:, FEATURE_CATE] = imp_mean.transform(processed_data[FEATURE_CATE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in processed_data.columns:\n",
    "    if col in FEATURE_CATE:\n",
    "        processed_data[col] = processed_data[col].astype('category').reset_index(drop=True)\n",
    "    if col in FEATURE_NUM:\n",
    "        processed_data[col] = processed_data[col].astype('float').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count Appointment with multiple rows')\n",
    "processed_data_grouped = processed_data.groupby('AppointmentSerNum')\n",
    "count_appt = processed_data_grouped.count()\n",
    "appt_one_list = count_appt[count_appt.Sex == 1].index.tolist()\n",
    "appt_more_list = count_appt[count_appt.Sex > 1].index.tolist()\n",
    "print(f'{len(appt_one_list)} with one appointment')\n",
    "print(f'{len(appt_more_list)} with more appointment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字也能够正常处理，比如出现0，同样会正常处理，并不会认为0 是没有值\n",
    "def one_hot_enc(feature, data):\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "    one_hot_encoder.fit(data[[feature]])\n",
    "    return one_hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_encoder_dxt_AliasName = one_hot_enc('dxt_AliasName', processed_data)\n",
    "label_encoder_Sex = one_hot_enc('Sex', processed_data)\n",
    "label_encoder_AliasSerNum = one_hot_enc('AliasSerNum', processed_data)\n",
    "label_encoder_month = one_hot_enc('month', processed_data)\n",
    "label_encoder_week = one_hot_enc('week', processed_data)\n",
    "label_encoder_hour = one_hot_enc('hour', processed_data)\n",
    "label_encoder_DoctorSerNum = one_hot_enc('DoctorSerNum', processed_data)\n",
    "label_encoder_TreatmentOrientation = one_hot_enc('TreatmentOrientation', processed_data)\n",
    "label_encoder_FractionNumber = one_hot_enc('FractionNumber', processed_data)\n",
    "label_encoder_UserName = one_hot_enc('UserName', processed_data)\n",
    "label_encoder_CourseId = one_hot_enc('CourseId', processed_data)\n",
    "label_encoder_ResourceSerNum = one_hot_enc('ResourceSerNum', processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple values in one-appointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_mul_row_appt(data_part1):\n",
    "    new_appt = pd.DataFrame({})\n",
    "\n",
    "    print('Start cateorical features')\n",
    "    print('\\nStart PatientSerNum')\n",
    "    new_appt['PatientSerNum'] = data_part1.groupby('AppointmentSerNum').PatientSerNum.apply(set)\n",
    "    new_appt['PatientSerNum'] = new_appt['PatientSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start Sex')\n",
    "    new_appt['Sex'] = data_part1.groupby('AppointmentSerNum').Sex.apply(set)\n",
    "    new_appt['Sex'] = new_appt['Sex'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start DoctorSerNum')\n",
    "    new_appt['DoctorSerNum'] = data_part1.groupby('AppointmentSerNum').DoctorSerNum.apply(set)\n",
    "    new_appt['DoctorSerNum'] = new_appt['DoctorSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start date')\n",
    "    new_appt['date'] = data_part1.groupby('AppointmentSerNum').date.apply(set)\n",
    "    new_appt['date'] = new_appt['date'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start ScheduledStartTime')\n",
    "    new_appt['ScheduledStartTime'] = data_part1.groupby('AppointmentSerNum').ScheduledStartTime.apply(set)\n",
    "    new_appt['ScheduledStartTime'] = new_appt['ScheduledStartTime'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start ScheduledEndTime')\n",
    "    new_appt['ScheduledEndTime'] = data_part1.groupby('AppointmentSerNum').ScheduledEndTime.apply(set)\n",
    "    new_appt['ScheduledEndTime'] = new_appt['ScheduledEndTime'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start ActualStartDate')\n",
    "    new_appt['ActualStartDate'] = data_part1.groupby('AppointmentSerNum').ActualStartDate.apply(set)\n",
    "    new_appt['ActualStartDate'] = new_appt['ActualStartDate'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start ActualEndDate')\n",
    "    new_appt['ActualEndDate'] = data_part1.groupby('AppointmentSerNum').ActualEndDate.apply(set)\n",
    "    new_appt['ActualEndDate'] = new_appt['ActualEndDate'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start dxt_AliasName')\n",
    "    new_appt['dxt_AliasName'] = data_part1.groupby('AppointmentSerNum').dxt_AliasName.apply(set)\n",
    "    new_appt['dxt_AliasName'] = new_appt['dxt_AliasName'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start AliasSerNum')\n",
    "    new_appt['AliasSerNum'] = data_part1.groupby('AppointmentSerNum').AliasSerNum.apply(set)\n",
    "    new_appt['AliasSerNum'] = new_appt['AliasSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start CourseSerNum')\n",
    "    new_appt['CourseSerNum'] = data_part1.groupby('AppointmentSerNum').CourseSerNum.apply(set)\n",
    "    new_appt['CourseSerNum'] = new_appt['CourseSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start PlanSerNum')\n",
    "    new_appt['PlanSerNum'] = data_part1.groupby('AppointmentSerNum').PlanSerNum.apply(set)\n",
    "    new_appt['PlanSerNum'] = new_appt['PlanSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start TreatmentOrientation')\n",
    "    new_appt['TreatmentOrientation'] = data_part1.groupby('AppointmentSerNum').TreatmentOrientation.apply(set)\n",
    "    new_appt['TreatmentOrientation'] = new_appt['TreatmentOrientation'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start month')\n",
    "    new_appt['month'] = data_part1.groupby('AppointmentSerNum').month.apply(set)\n",
    "    new_appt['month'] = new_appt['month'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start week')\n",
    "    new_appt['week'] = data_part1.groupby('AppointmentSerNum').week.apply(set)\n",
    "    new_appt['week'] = new_appt['week'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start hour')\n",
    "    new_appt['hour'] = data_part1.groupby('AppointmentSerNum').hour.apply(set)\n",
    "    new_appt['hour'] = new_appt['hour'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start AppointmentSerNum')\n",
    "    new_appt['AppointmentSerNum'] = new_appt.index.tolist()\n",
    "\n",
    "\n",
    "    print('Start numberical features')\n",
    "    print('\\nStart age')\n",
    "    new_appt['age'] = data_part1.groupby('AppointmentSerNum').age.mean()\n",
    "\n",
    "    print('Start Scheduled_duration')\n",
    "    new_appt['Scheduled_duration'] = data_part1.groupby('AppointmentSerNum').Scheduled_duration.mean()\n",
    "\n",
    "    print('Start Actual_duration')\n",
    "    new_appt['Actual_duration'] = data_part1.groupby('AppointmentSerNum').Actual_duration.mean()\n",
    "    \n",
    "    new_appt.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return new_appt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_mul_row_treat(data_part2):\n",
    "    new_treat = pd.DataFrame({})\n",
    "\n",
    "    print('Start categorical features')\n",
    "    print('\\nStart FractionNumber')\n",
    "    new_treat['FractionNumber'] = data_part2.groupby(['PatientSerNum', 'date']).FractionNumber.apply(set)\n",
    "    new_treat['FractionNumber'] = new_treat['FractionNumber'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start UserName')\n",
    "    new_treat['UserName'] = data_part2.groupby(['PatientSerNum', 'date']).UserName.apply(set)\n",
    "    new_treat['UserName'] = new_treat['UserName'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start RadiationSerNum')\n",
    "    new_treat['RadiationSerNum'] = data_part2.groupby(['PatientSerNum', 'date']).RadiationSerNum.apply(set)\n",
    "    new_treat['RadiationSerNum'] = new_treat['RadiationSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start ResourceSerNum')\n",
    "    new_treat['ResourceSerNum'] = data_part2.groupby(['PatientSerNum', 'date']).ResourceSerNum.apply(set)\n",
    "    new_treat['ResourceSerNum'] = new_treat['ResourceSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start CourseId')\n",
    "    new_treat['CourseId'] = data_part2.groupby(['PatientSerNum', 'date']).CourseId.apply(set)\n",
    "    new_treat['CourseId'] = new_treat['CourseId'].apply(lambda x: get_list(x))\n",
    "\n",
    "    print('Start PatientSerNum')\n",
    "    new_treat['PatientSerNum'] = new_treat.index.get_level_values(level = 0).tolist()\n",
    "\n",
    "    print('Start date')\n",
    "    new_treat['date'] = new_treat.index.get_level_values(level = 1).tolist()\n",
    "    \n",
    "    \n",
    "    print('Start numberical features')\n",
    "    print('\\nStart ImagesTaken_total')\n",
    "    new_treat['ImagesTaken_total'] = data_part2.groupby(['PatientSerNum', 'date']).ImagesTaken.sum()\n",
    "\n",
    "    print('Start MU_total')\n",
    "    new_treat['MU_total'] = data_part2.groupby(['PatientSerNum', 'date']).MU.sum()\n",
    "\n",
    "    print('Start MUCoeff_total')\n",
    "    new_treat['MUCoeff_total'] = data_part2.groupby(['PatientSerNum', 'date']).MUCoeff.sum()\n",
    "\n",
    "    print('Start TreatmentTime_total')\n",
    "    new_treat['TreatmentTime_total'] = data_part2.groupby(['PatientSerNum', 'date']).TreatmentTime.sum()\n",
    "    \n",
    "    new_treat.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return new_treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Combine Appointment with multiple rows\n",
      "Start cateorical features\n",
      "\n",
      "Start PatientSerNum\n",
      "Start Sex\n",
      "Start DoctorSerNum\n",
      "Start date\n",
      "Start ScheduledStartTime\n",
      "Start ScheduledEndTime\n",
      "Start ActualStartDate\n",
      "Start ActualEndDate\n",
      "Start dxt_AliasName\n",
      "Start AliasSerNum\n",
      "Start CourseSerNum\n",
      "Start PlanSerNum\n",
      "Start TreatmentOrientation\n",
      "Start month\n",
      "Start week\n",
      "Start hour\n",
      "Start AppointmentSerNum\n",
      "Start numberical features\n",
      "\n",
      "Start age\n",
      "Start Scheduled_duration\n",
      "Start Actual_duration\n",
      "The shape of new_appt is (139944, 20)\n",
      "Start categorical features\n",
      "\n",
      "Start FractionNumber\n",
      "Start UserName\n",
      "Start RadiationSerNum\n",
      "Start ResourceSerNum\n",
      "Start CourseId\n",
      "Start PatientSerNum\n",
      "Start date\n",
      "Start numberical features\n",
      "\n",
      "Start ImagesTaken_total\n",
      "Start MU_total\n",
      "Start MUCoeff_total\n",
      "Start TreatmentTime_total\n",
      "The shape of new_treat is (139277, 11)\n"
     ]
    }
   ],
   "source": [
    "# 将相同的AppointmentSerNum 的信息进行合并\n",
    "print('='*40)\n",
    "print('Combine Appointment with multiple rows')\n",
    "new_appt = combine_mul_row_appt(processed_data)\n",
    "print(f'The shape of new_appt is {new_appt.shape}')\n",
    "new_treat = combine_mul_row_treat(processed_data)\n",
    "print(f'The shape of new_treat is {new_treat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Merge data_appt and data_treat\n",
      "The shape of data is (139944, 29)\n"
     ]
    }
   ],
   "source": [
    "# 将appt 和treat 信息进行合并，得到DATA\n",
    "print('='*40)\n",
    "print('Merge data_appt and data_treat')\n",
    "DATA = pd.merge(new_appt, new_treat, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "DATA = DATA.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime']).reset_index(drop=True)\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Filter data\n",
      "The shape of data is (126936, 29)\n"
     ]
    }
   ],
   "source": [
    "# 筛选后的DATA\n",
    "print('='*40)\n",
    "print('Filter data')\n",
    "DATA_ = DATA[(DATA.Actual_duration >= 10) & (DATA.Actual_duration <= 60)].reset_index(drop=True)\n",
    "print(f'The shape of data is {DATA_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_NUM_FEATURES = ['Scheduled_duration', 'Actual_duration',\n",
    "                   'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "                   'MU_total', 'MUCoeff_total', 'Interval_scheduled']\n",
    "\n",
    "# RadiationId\n",
    "NN_CATE_FEATURES = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "                    'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                    'TreatmentOrientation', 'FractionNumber',\n",
    "                    'UserName', 'CourseId', 'ResourceSerNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Select Patient with one more Appointment\n",
      "series_seq 8101\n",
      "series_one 862\n",
      "The total number of patient is 8101\n",
      "The max length of patient is 80\n",
      "The number of input encoded-feature is 441\n"
     ]
    }
   ],
   "source": [
    "# 只保留存在一个以上Appointment 的患者\n",
    "print('='*40)\n",
    "print('Select Patient with one more Appointment')\n",
    "DATA_grouped = DATA_.groupby('PatientSerNum')\n",
    "series_count = DATA_grouped.count()\n",
    "series_seq = series_count[series_count.AppointmentSerNum > 1].index.tolist()\n",
    "series_one = series_count[series_count.AppointmentSerNum == 1].index.tolist()\n",
    "print(f'series_seq {len(series_seq)}')\n",
    "print(f'series_one {len(series_one)}')\n",
    "series_seq = pd.DataFrame({'PatientSerNum': series_seq})\n",
    "series_data = pd.merge(series_seq, DATA, on = 'PatientSerNum', how = 'inner')\n",
    "series_data.sort_values(by = ['PatientSerNum', 'ScheduledStartTime'], inplace = True)\n",
    "\n",
    "\n",
    "# 符合条件的患者的序列，全部课用样本\n",
    "series_data_grouped = series_data.groupby('PatientSerNum')\n",
    "pat_list = shuffle(list(series_data_grouped.groups.keys()), random_state = 1)\n",
    "print(f'The total number of patient is {len(pat_list)}')\n",
    "\n",
    "\n",
    "# 因为使用非固定长度的样本进行训练，因此 APPT_LEN没有用\n",
    "# FEATURE_LEN 是根据编码后的结果到的\n",
    "# 后面的编码由于存在，一个样本中多个值的情况，因此一次一个样本进行one hot 的转化（没想出更好的办法解决这一问题）\n",
    "APPT_LEN = series_data_grouped.count().AppointmentSerNum.max()\n",
    "FEATURE_LEN = 441\n",
    "print(f'The max length of patient is {APPT_LEN}')\n",
    "print(f'The number of input encoded-feature is {FEATURE_LEN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Generate Samples and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(train_sample_):\n",
    "    train_sample = train_sample_.reset_index(drop=True)\n",
    "\n",
    "    # 样本标签\n",
    "    train_y = np.array([train_sample.Actual_duration.iloc[-1]])\n",
    "    \n",
    "    # 最后一个appointment 为我们需要预测的真实治疗时长所对应的appointment，所以需要设置为0\n",
    "    train_sample.Actual_duration.iloc[-1] = 0\n",
    "\n",
    "    # 因为存在相隔很远的两次预约，因此，构造特征Interval_scheduled 来度量两次预约之间的距离\n",
    "    # 上一次的预期治疗开始时间\n",
    "    train_sample['Last_ScheduledStartTime'] = train_sample.ScheduledStartTime.shift(\n",
    "        periods = 1, fill_value = train_sample.ScheduledStartTime.iloc[0])\n",
    "    train_sample['Interval_scheduled'] = train_sample.apply(\n",
    "        lambda x: (x.ScheduledStartTime - x.Last_ScheduledStartTime).days, axis = 1)\n",
    "    \n",
    "    # 对分类变量进行one-hot encoding处理\n",
    "    encode_cate = pd.DataFrame({})\n",
    "    \n",
    "    # 这个地方将Sex 作为序列的一部分，并不是在最后的隐藏层进行合并\n",
    "    encode_cate['Sex'] = train_sample['Sex'].apply(\n",
    "        lambda x: sum(label_encoder_Sex.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.vstack(encode_cate.Sex.tolist())\n",
    "    \n",
    "    encode_cate['dxt_AliasName'] = train_sample['dxt_AliasName'].apply(\n",
    "        lambda x: sum(label_encoder_dxt_AliasName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.dxt_AliasName.tolist())))\n",
    "\n",
    "    train_sample['AliasSerNum'] = train_sample['AliasSerNum'].astype(str)\n",
    "    encode_cate['AliasSerNum'] = train_sample['AliasSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_AliasSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.AliasSerNum.tolist())))\n",
    "\n",
    "    encode_cate['month'] = train_sample['month'].apply(\n",
    "        lambda x: sum(label_encoder_month.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.month.tolist())))\n",
    "\n",
    "    encode_cate['week'] = train_sample['week'].apply(\n",
    "        lambda x: sum(label_encoder_week.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.week.tolist())))\n",
    "\n",
    "    encode_cate['hour'] = train_sample['hour'].apply(\n",
    "        lambda x: sum(label_encoder_hour.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.hour.tolist())))\n",
    "\n",
    "    encode_cate['DoctorSerNum'] = train_sample['DoctorSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_DoctorSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.DoctorSerNum.tolist())))\n",
    "\n",
    "    encode_cate['TreatmentOrientation'] = train_sample['TreatmentOrientation'].apply(\n",
    "        lambda x: sum(label_encoder_TreatmentOrientation.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.TreatmentOrientation.tolist())))\n",
    "\n",
    "    encode_cate['FractionNumber'] = train_sample['FractionNumber'].apply(\n",
    "        lambda x: sum(label_encoder_FractionNumber.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.FractionNumber.tolist())))\n",
    "\n",
    "    encode_cate['UserName'] = train_sample['UserName'].apply(\n",
    "        lambda x: sum(label_encoder_UserName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.UserName.tolist())))\n",
    "\n",
    "    encode_cate['CourseId'] = train_sample['CourseId'].apply(\n",
    "        lambda x: sum(label_encoder_CourseId.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.CourseId.tolist())))\n",
    "\n",
    "    encode_cate['ResourceSerNum'] = train_sample['ResourceSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_ResourceSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.ResourceSerNum.tolist())))\n",
    "    \n",
    "    # 将数值变量和非数值变量进行合并\n",
    "    train_num = train_sample[NN_NUM_FEATURES]\n",
    "    train_x = np.hstack((train_x, train_num))\n",
    "\n",
    "    train_x[np.isnan(train_x)]=0\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               219136    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 223,297\n",
      "Trainable params: 223,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 不指定时间戳长度\n",
    "model_sequence = Sequential()\n",
    "model_sequence.add(\n",
    "    layers.LSTM(128,\n",
    "        batch_input_shape = (None , None, 299),\n",
    "        dropout=0.1,\n",
    "        recurrent_dropout=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "# model_sequence.add(layers.LSTM(\n",
    "#         output_dim = 32,\n",
    "#         ))\n",
    "# stateful = True 本次batch的参数返回到下一次的训练中\n",
    "\n",
    "model_sequence.add(layers.Dense(32))\n",
    "\n",
    "model_sequence.add(layers.Dense(1))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "model_sequence.compile(\n",
    "        optimizer = adam,\n",
    "        loss = 'mae'\n",
    "        )\n",
    "\n",
    "model_sequence.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train_list 7695\n",
      "The number of test_list 406\n"
     ]
    }
   ],
   "source": [
    "pat_list = shuffle(pat_list)\n",
    "train_list = pat_list[: int(0.95*len(pat_list))]\n",
    "print(f'The number of train_list {len(train_list)}')\n",
    "# val_list = pat_list[int(0.8*len(pat_list)): int(0.9*len(pat_list))]\n",
    "# print(f'The number of val_list {len(val_list)}')\n",
    "test_list = pat_list[int(0.95*len(pat_list)): ]\n",
    "print(f'The number of test_list {len(test_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Start training\n",
      "\n",
      "Batch 1.0 train loss 1.0 14.589589576721192\n",
      "\n",
      "Batch 1.0 validation loss 7.131570637519724\n",
      "\n",
      "Batch 2.0 train loss 2.0 8.047772035598754\n",
      "\n",
      "Batch 2.0 validation loss 6.479349749428885\n",
      "\n",
      "Batch 3.0 train loss 3.0 6.340031099319458\n",
      "\n",
      "Batch 3.0 validation loss 6.627906146307884\n",
      "\n",
      "Batch 4.0 train loss 4.0 6.754651889801026\n",
      "\n",
      "Batch 4.0 validation loss 6.193003788370217\n",
      "\n",
      "Batch 5.0 train loss 5.0 5.2847356033325195\n",
      "\n",
      "Batch 5.0 validation loss 6.07071366098714\n",
      "\n",
      "Batch 6.0 train loss 6.0 4.485616455078125\n",
      "\n",
      "Batch 6.0 validation loss 6.317784548980262\n",
      "\n",
      "Batch 7.0 train loss 7.0 5.908207855224609\n",
      "\n",
      "Batch 7.0 validation loss 6.200028186948429\n",
      "\n",
      "Batch 8.0 train loss 8.0 6.495274000167846\n",
      "\n",
      "Batch 8.0 validation loss 6.150089195796421\n",
      "\n",
      "Batch 9.0 train loss 9.0 5.446436786651612\n",
      "\n",
      "Batch 9.0 validation loss 5.935462857702095\n",
      "\n",
      "Batch 10.0 train loss 10.0 7.221195058822632\n",
      "\n",
      "Batch 10.0 validation loss 5.899503437756318\n",
      "\n",
      "Batch 11.0 train loss 11.0 6.110713748931885\n",
      "\n",
      "Batch 11.0 validation loss 5.909816861739887\n",
      "\n",
      "Batch 12.0 train loss 12.0 8.6258717918396\n",
      "\n",
      "Batch 12.0 validation loss 6.051307401046377\n",
      "\n",
      "Batch 13.0 train loss 13.0 4.327559890747071\n",
      "\n",
      "Batch 13.0 validation loss 6.053797336634744\n",
      "\n",
      "Batch 14.0 train loss 14.0 6.519562225341797\n",
      "\n",
      "Batch 14.0 validation loss 6.195481894638738\n",
      "\n",
      "Batch 15.0 train loss 15.0 5.416031093597412\n",
      "\n",
      "Batch 15.0 validation loss 5.896782149235016\n",
      "\n",
      "Batch 16.0 train loss 16.0 5.3820204925537105\n",
      "\n",
      "Batch 16.0 validation loss 5.940239906311035\n",
      "\n",
      "Batch 17.0 train loss 17.0 7.708002700805664\n",
      "\n",
      "Batch 17.0 validation loss 6.087937641613589\n",
      "\n",
      "Batch 18.0 train loss 18.0 5.905207500457764\n",
      "\n",
      "Batch 18.0 validation loss 5.835107260736926\n",
      "\n",
      "Batch 19.0 train loss 19.0 6.343805255889893\n",
      "\n",
      "Batch 19.0 validation loss 5.770077010093652\n",
      "\n",
      "Batch 20.0 train loss 20.0 5.497434730529785\n",
      "\n",
      "Batch 20.0 validation loss 5.70518152114793\n",
      "\n",
      "Batch 21.0 train loss 21.0 5.867367124557495\n",
      "\n",
      "Batch 21.0 validation loss 5.7712311040004485\n",
      "\n",
      "Batch 22.0 train loss 22.0 5.931301527023315\n",
      "\n",
      "Batch 22.0 validation loss 6.13504515023067\n",
      "\n",
      "Batch 23.0 train loss 23.0 7.59198564529419\n",
      "\n",
      "Batch 23.0 validation loss 5.952818163510027\n",
      "\n",
      "Batch 24.0 train loss 24.0 5.102242126464843\n",
      "\n",
      "Batch 24.0 validation loss 6.167306705061438\n",
      "\n",
      "Batch 25.0 train loss 25.0 6.576468048095703\n",
      "\n",
      "Batch 25.0 validation loss 5.924892235272036\n",
      "\n",
      "Batch 26.0 train loss 26.0 8.178867263793945\n",
      "\n",
      "Batch 26.0 validation loss 5.767960235990327\n",
      "\n",
      "Batch 27.0 train loss 27.0 5.143946161270142\n",
      "\n",
      "Batch 27.0 validation loss 5.650239902176881\n",
      "\n",
      "Batch 28.0 train loss 28.0 7.423497657775879\n",
      "\n",
      "Batch 28.0 validation loss 5.9219471480458825\n",
      "\n",
      "Batch 29.0 train loss 29.0 4.455903873443604\n",
      "\n",
      "Batch 29.0 validation loss 5.949260418050982\n",
      "\n",
      "Batch 30.0 train loss 30.0 7.202807064056397\n",
      "\n",
      "Batch 30.0 validation loss 5.904121809992297\n",
      "\n",
      "Batch 31.0 train loss 31.0 28.052529916763305\n",
      "\n",
      "Batch 31.0 validation loss 6.339674127512965\n",
      "\n",
      "Batch 32.0 train loss 32.0 5.45485631942749\n",
      "\n",
      "Batch 32.0 validation loss 5.783548225910206\n",
      "\n",
      "Batch 33.0 train loss 33.0 6.816069459915161\n",
      "\n",
      "Batch 33.0 validation loss 5.725308514580938\n",
      "\n",
      "Batch 34.0 train loss 34.0 6.97850959777832\n",
      "\n",
      "Batch 34.0 validation loss 5.837154346146607\n",
      "\n",
      "Batch 35.0 train loss 35.0 5.784725522994995\n",
      "\n",
      "Batch 35.0 validation loss 5.802462206685484\n",
      "\n",
      "Batch 36.0 train loss 36.0 4.793258323669433\n",
      "\n",
      "Batch 36.0 validation loss 5.913584032669443\n",
      "\n",
      "Batch 37.0 train loss 37.0 5.734216251373291\n",
      "\n",
      "Batch 37.0 validation loss 5.726676588575241\n",
      "\n",
      "Batch 38.0 train loss 38.0 5.301693859100342\n",
      "\n",
      "Batch 38.0 validation loss 5.94238519433684\n",
      "\n",
      "Batch 39.0 train loss 39.0 5.571495170593262\n",
      "\n",
      "Batch 39.0 validation loss 5.858915998430675\n",
      "\n",
      "Batch 40.0 train loss 40.0 5.896541481018066\n",
      "\n",
      "Batch 40.0 validation loss 6.141945110753252\n",
      "\n",
      "Batch 41.0 train loss 41.0 4.936996154785156\n",
      "\n",
      "Batch 41.0 validation loss 5.838083751095927\n",
      "\n",
      "Batch 42.0 train loss 42.0 5.142889337539673\n",
      "\n",
      "Batch 42.0 validation loss 6.109070836616854\n",
      "\n",
      "Batch 43.0 train loss 43.0 5.743576965332031\n",
      "\n",
      "Batch 43.0 validation loss 5.916599005901167\n",
      "\n",
      "Batch 44.0 train loss 44.0 6.638465309143067\n",
      "\n",
      "Batch 44.0 validation loss 6.30204926570648\n",
      "\n",
      "Batch 45.0 train loss 45.0 7.477507257461548\n",
      "\n",
      "Batch 45.0 validation loss 5.779180125062688\n",
      "\n",
      "Batch 46.0 train loss 46.0 6.332302541732788\n",
      "\n",
      "Batch 46.0 validation loss 5.872613277341345\n",
      "\n",
      "Batch 47.0 train loss 47.0 5.754497566223145\n",
      "\n",
      "Batch 47.0 validation loss 5.900768653512588\n",
      "\n",
      "Batch 48.0 train loss 48.0 4.092876691818237\n",
      "\n",
      "Batch 48.0 validation loss 6.00059839305032\n",
      "\n",
      "Batch 49.0 train loss 49.0 5.244206209182739\n",
      "\n",
      "Batch 49.0 validation loss 5.836615907734838\n",
      "\n",
      "Batch 50.0 train loss 50.0 6.395531339645386\n",
      "\n",
      "Batch 50.0 validation loss 5.930749085149154\n",
      "\n",
      "Batch 51.0 train loss 51.0 5.982498989105225\n",
      "\n",
      "Batch 51.0 validation loss 5.859586025106496\n",
      "\n",
      "Batch 52.0 train loss 52.0 7.377482833862305\n",
      "\n",
      "Batch 52.0 validation loss 6.436129941141664\n",
      "\n",
      "Batch 53.0 train loss 53.0 5.84478214263916\n",
      "\n",
      "Batch 53.0 validation loss 5.867707856182982\n",
      "\n",
      "Batch 54.0 train loss 54.0 6.733285369873047\n",
      "\n",
      "Batch 54.0 validation loss 6.658625447691367\n",
      "\n",
      "Batch 55.0 train loss 55.0 4.376709880828858\n",
      "\n",
      "Batch 55.0 validation loss 5.991048326633247\n",
      "\n",
      "Batch 56.0 train loss 56.0 6.529618635177612\n",
      "\n",
      "Batch 56.0 validation loss 5.901936575696974\n",
      "\n",
      "Batch 57.0 train loss 57.0 8.10393931388855\n",
      "\n",
      "Batch 57.0 validation loss 5.859203538283926\n",
      "\n",
      "Batch 58.0 train loss 58.0 6.068708591461181\n",
      "\n",
      "Batch 58.0 validation loss 5.936762199026023\n",
      "\n",
      "Batch 59.0 train loss 59.0 6.012462882995606\n",
      "\n",
      "Batch 59.0 validation loss 5.952560993250955\n",
      "\n",
      "Batch 60.0 train loss 60.0 27.41212408065796\n",
      "\n",
      "Batch 60.0 validation loss 5.996206779198106\n",
      "\n",
      "Batch 61.0 train loss 61.0 7.0290779113769535\n",
      "\n",
      "Batch 61.0 validation loss 5.94289337355515\n",
      "\n",
      "Batch 62.0 train loss 62.0 6.106812210083008\n",
      "\n",
      "Batch 62.0 validation loss 6.053843167027816\n",
      "\n",
      "Batch 63.0 train loss 63.0 4.998636417388916\n",
      "\n",
      "Batch 63.0 validation loss 5.843317144610024\n",
      "\n",
      "Batch 64.0 train loss 64.0 6.6100091457366945\n",
      "\n",
      "Batch 64.0 validation loss 5.872592465630893\n",
      "\n",
      "Batch 65.0 train loss 65.0 4.615546216964722\n",
      "\n",
      "Batch 65.0 validation loss 5.89092930901814\n",
      "\n",
      "Batch 66.0 train loss 66.0 5.844228715896606\n",
      "\n",
      "Batch 66.0 validation loss 6.035212537925232\n",
      "\n",
      "Batch 67.0 train loss 67.0 5.1721532440185545\n",
      "\n",
      "Batch 67.0 validation loss 5.97260602941654\n",
      "\n",
      "Batch 68.0 train loss 68.0 7.16534683227539\n",
      "\n",
      "Batch 68.0 validation loss 5.8744574814594435\n",
      "\n",
      "Batch 69.0 train loss 69.0 5.966197834014893\n",
      "\n",
      "Batch 69.0 validation loss 5.8628800443827815\n",
      "\n",
      "Batch 70.0 train loss 70.0 4.392524147033692\n",
      "\n",
      "Batch 70.0 validation loss 5.8069941609951075\n",
      "\n",
      "Batch 71.0 train loss 71.0 6.619319467544556\n",
      "\n",
      "Batch 71.0 validation loss 6.904249275846435\n",
      "\n",
      "Batch 72.0 train loss 72.0 7.038776626586914\n",
      "\n",
      "Batch 72.0 validation loss 6.5493436705302726\n",
      "\n",
      "Batch 73.0 train loss 73.0 6.104557895660401\n",
      "\n",
      "Batch 73.0 validation loss 5.89332479561491\n",
      "\n",
      "Batch 74.0 train loss 74.0 5.1949364280700685\n",
      "\n",
      "Batch 74.0 validation loss 5.719257291314637\n",
      "\n",
      "Batch 75.0 train loss 75.0 6.1436191749572755\n",
      "\n",
      "Batch 75.0 validation loss 6.531326401997083\n",
      "\n",
      "Batch 76.0 train loss 76.0 4.650192203521729\n",
      "\n",
      "Batch 76.0 validation loss 6.1551609297691305\n",
      "\n",
      "Batch 77.0 train loss 77.0 6.875868892669677\n",
      "\n",
      "Batch 77.0 validation loss 6.055254189251679\n",
      "\n",
      "Batch 78.0 train loss 78.0 5.688241291046142\n",
      "\n",
      "Batch 78.0 validation loss 5.982676846640451\n",
      "\n",
      "Batch 79.0 train loss 79.0 5.2963430786132815\n",
      "\n",
      "Batch 79.0 validation loss 6.07481570314304\n",
      "\n",
      "Batch 80.0 train loss 80.0 6.293449325561523\n",
      "\n",
      "Batch 80.0 validation loss 6.039287196004332\n",
      "\n",
      "Batch 81.0 train loss 81.0 6.190462598800659\n",
      "\n",
      "Batch 81.0 validation loss 6.010491653028967\n",
      "\n",
      "Batch 82.0 train loss 82.0 5.316039981842041\n",
      "\n",
      "Batch 82.0 validation loss 6.014139938824282\n",
      "\n",
      "Batch 83.0 train loss 83.0 5.830085401535034\n",
      "\n",
      "Batch 83.0 validation loss 6.146519616319628\n",
      "\n",
      "Batch 84.0 train loss 84.0 5.980716056823731\n",
      "\n",
      "Batch 84.0 validation loss 6.011183391063671\n",
      "\n",
      "Batch 85.0 train loss 85.0 7.444691181182861\n",
      "\n",
      "Batch 85.0 validation loss 6.08843975583908\n",
      "\n",
      "Batch 86.0 train loss 86.0 5.5359894561767575\n",
      "\n",
      "Batch 86.0 validation loss 5.942044152414858\n",
      "\n",
      "Batch 87.0 train loss 87.0 6.782381286621094\n",
      "\n",
      "Batch 87.0 validation loss 6.085547604584342\n",
      "\n",
      "Batch 88.0 train loss 88.0 5.630948963165284\n",
      "\n",
      "Batch 88.0 validation loss 5.971465986937725\n",
      "\n",
      "Batch 89.0 train loss 89.0 6.770023250579834\n",
      "\n",
      "Batch 89.0 validation loss 5.981405037377268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 90.0 train loss 90.0 5.822280921936035\n",
      "\n",
      "Batch 90.0 validation loss 5.9394423292188225\n",
      "\n",
      "Batch 91.0 train loss 91.0 8.0966575050354\n",
      "\n",
      "Batch 91.0 validation loss 6.069568681012234\n",
      "\n",
      "Batch 92.0 train loss 92.0 7.692733602523804\n",
      "\n",
      "Batch 92.0 validation loss 5.980375266427477\n",
      "\n",
      "Batch 93.0 train loss 93.0 4.594138088226319\n",
      "\n",
      "Batch 93.0 validation loss 6.100936504420389\n",
      "\n",
      "Batch 94.0 train loss 94.0 5.621616477966309\n",
      "\n",
      "Batch 94.0 validation loss 5.84772304008747\n",
      "\n",
      "Batch 95.0 train loss 95.0 4.782088871002197\n",
      "\n",
      "Batch 95.0 validation loss 5.924538541897177\n",
      "\n",
      "Batch 96.0 train loss 96.0 6.88336485862732\n",
      "\n",
      "Batch 96.0 validation loss 5.838412916719033\n",
      "\n",
      "Batch 97.0 train loss 97.0 6.415655908584594\n",
      "\n",
      "Batch 97.0 validation loss 5.823845903274461\n",
      "\n",
      "Batch 98.0 train loss 98.0 7.185600204467773\n",
      "\n",
      "Batch 98.0 validation loss 5.93386143886397\n",
      "\n",
      "Batch 99.0 train loss 99.0 5.4102555274963375\n",
      "\n",
      "Batch 99.0 validation loss 5.838242436864693\n",
      "\n",
      "Batch 100.0 train loss 100.0 5.189827318191528\n",
      "\n",
      "Batch 100.0 validation loss 5.971439610561126\n",
      "\n",
      "Batch 101.0 train loss 101.0 4.954855794906616\n",
      "\n",
      "Batch 101.0 validation loss 5.8648580635709715\n",
      "\n",
      "Batch 102.0 train loss 102.0 5.61599796295166\n",
      "\n",
      "Batch 102.0 validation loss 5.991559707472477\n",
      "\n",
      "Batch 103.0 train loss 103.0 5.978507137298584\n",
      "\n",
      "Batch 103.0 validation loss 5.913590313765803\n",
      "\n",
      "Batch 104.0 train loss 104.0 5.290376796722412\n",
      "\n",
      "Batch 104.0 validation loss 5.912276392499802\n",
      "\n",
      "Batch 105.0 train loss 105.0 6.208113203048706\n",
      "\n",
      "Batch 105.0 validation loss 5.749705624697831\n",
      "\n",
      "Batch 106.0 train loss 106.0 5.36415620803833\n",
      "\n",
      "Batch 106.0 validation loss 5.959950461176229\n",
      "\n",
      "Batch 107.0 train loss 107.0 6.187353687286377\n",
      "\n",
      "Batch 107.0 validation loss 5.79452280223076\n",
      "\n",
      "Batch 108.0 train loss 108.0 5.551219024658203\n",
      "\n",
      "Batch 108.0 validation loss 5.796684807744519\n",
      "\n",
      "Batch 109.0 train loss 109.0 6.168371524810791\n",
      "\n",
      "Batch 109.0 validation loss 5.854914989377478\n",
      "\n",
      "Batch 110.0 train loss 110.0 5.639214172363281\n",
      "\n",
      "Batch 110.0 validation loss 5.686068276466407\n",
      "\n",
      "Batch 111.0 train loss 111.0 5.459236583709717\n",
      "\n",
      "Batch 111.0 validation loss 5.884958448081181\n",
      "\n",
      "Batch 112.0 train loss 112.0 6.3131655502319335\n",
      "\n",
      "Batch 112.0 validation loss 5.863393980881264\n",
      "\n",
      "Batch 113.0 train loss 113.0 7.013462352752685\n",
      "\n",
      "Batch 113.0 validation loss 5.861270082407985\n",
      "\n",
      "Batch 114.0 train loss 114.0 5.085460042953491\n",
      "\n",
      "Batch 114.0 validation loss 5.760416585236348\n",
      "\n",
      "Batch 115.0 train loss 115.0 4.429518299102783\n",
      "\n",
      "Batch 115.0 validation loss 5.795453529639785\n",
      "\n",
      "Batch 116.0 train loss 116.0 6.78933819770813\n",
      "\n",
      "Batch 116.0 validation loss 6.178959275701363\n",
      "\n",
      "Batch 117.0 train loss 117.0 4.310655040740967\n",
      "\n",
      "Batch 117.0 validation loss 5.895667245235349\n",
      "\n",
      "Batch 118.0 train loss 118.0 5.25433765411377\n",
      "\n",
      "Batch 118.0 validation loss 5.786572980176052\n",
      "\n",
      "Batch 119.0 train loss 119.0 4.884430780410766\n",
      "\n",
      "Batch 119.0 validation loss 6.063479898011156\n",
      "\n",
      "Batch 120.0 train loss 120.0 5.026102771759033\n",
      "\n",
      "Batch 120.0 validation loss 5.902400864756166\n",
      "\n",
      "Batch 121.0 train loss 121.0 10.585071077346802\n",
      "\n",
      "Batch 121.0 validation loss 5.845647499479097\n",
      "\n",
      "Batch 122.0 train loss 122.0 5.212538604736328\n",
      "\n",
      "Batch 122.0 validation loss 6.103863344991148\n",
      "\n",
      "Batch 123.0 train loss 123.0 6.403299369812012\n",
      "\n",
      "Batch 123.0 validation loss 5.90057700960507\n",
      "\n",
      "Batch 124.0 train loss 124.0 5.993566942214966\n",
      "\n",
      "Batch 124.0 validation loss 5.99582254945351\n",
      "\n",
      "Batch 125.0 train loss 125.0 5.299303894042969\n",
      "\n",
      "Batch 125.0 validation loss 5.904382266434543\n",
      "\n",
      "Batch 126.0 train loss 126.0 5.343881778717041\n",
      "\n",
      "Batch 126.0 validation loss 5.8333743029627305\n",
      "\n",
      "Batch 127.0 train loss 127.0 5.312869148254395\n",
      "\n",
      "Batch 127.0 validation loss 5.806967343015624\n",
      "\n",
      "Batch 128.0 train loss 128.0 4.941944122314453\n",
      "\n",
      "Batch 128.0 validation loss 5.802272268116767\n",
      "\n",
      "Batch 129.0 train loss 129.0 6.532732591629029\n",
      "\n",
      "Batch 129.0 validation loss 5.792389399899638\n",
      "\n",
      "Batch 130.0 train loss 130.0 5.334905805587769\n",
      "\n",
      "Batch 130.0 validation loss 6.03461354119437\n",
      "\n",
      "Batch 131.0 train loss 131.0 6.8326081275939945\n",
      "\n",
      "Batch 131.0 validation loss 5.7621127936640395\n",
      "\n",
      "Batch 132.0 train loss 132.0 5.729572658538818\n",
      "\n",
      "Batch 132.0 validation loss 5.70852284360989\n",
      "\n",
      "Batch 133.0 train loss 133.0 5.337969980239868\n",
      "\n",
      "Batch 133.0 validation loss 5.718190202572075\n",
      "\n",
      "Batch 134.0 train loss 134.0 5.692215766906738\n",
      "\n",
      "Batch 134.0 validation loss 6.149399080887217\n",
      "\n",
      "Batch 135.0 train loss 135.0 6.679197759628296\n",
      "\n",
      "Batch 135.0 validation loss 5.737709538689975\n",
      "\n",
      "Batch 136.0 train loss 136.0 6.625095272064209\n",
      "\n",
      "Batch 136.0 validation loss 5.857755902952748\n",
      "\n",
      "Batch 137.0 train loss 137.0 5.598413753509521\n",
      "\n",
      "Batch 137.0 validation loss 5.911279873307703\n",
      "\n",
      "Batch 138.0 train loss 138.0 4.708821086883545\n",
      "\n",
      "Batch 138.0 validation loss 5.651520404909632\n",
      "\n",
      "Batch 139.0 train loss 139.0 5.004466867446899\n",
      "\n",
      "Batch 139.0 validation loss 5.844144201043791\n",
      "\n",
      "Batch 140.0 train loss 140.0 6.734674549102783\n",
      "\n",
      "Batch 140.0 validation loss 6.312508916619963\n",
      "\n",
      "Batch 141.0 train loss 141.0 5.882178840637207\n",
      "\n",
      "Batch 141.0 validation loss 6.001762058934554\n",
      "\n",
      "Batch 142.0 train loss 142.0 7.020736141204834\n",
      "\n",
      "Batch 142.0 validation loss 6.009529557721368\n",
      "\n",
      "Batch 143.0 train loss 143.0 8.85044361114502\n",
      "\n",
      "Batch 143.0 validation loss 6.0247611224357716\n",
      "\n",
      "Batch 144.0 train loss 144.0 5.162577228546143\n",
      "\n",
      "Batch 144.0 validation loss 5.757750887001676\n",
      "\n",
      "Batch 145.0 train loss 145.0 5.973445558547974\n",
      "\n",
      "Batch 145.0 validation loss 5.735659308034211\n",
      "\n",
      "Batch 146.0 train loss 146.0 6.292815647125244\n",
      "\n",
      "Batch 146.0 validation loss 5.792127778377439\n",
      "\n",
      "Batch 147.0 train loss 147.0 6.825985221862793\n",
      "\n",
      "Batch 147.0 validation loss 6.371942343970238\n",
      "\n",
      "Batch 148.0 train loss 148.0 6.495668697357178\n",
      "\n",
      "Batch 148.0 validation loss 5.904076712472098\n",
      "\n",
      "Batch 149.0 train loss 149.0 5.045285835266113\n",
      "\n",
      "Batch 149.0 validation loss 6.305393911934838\n",
      "\n",
      "Batch 150.0 train loss 150.0 7.282412471771241\n",
      "\n",
      "Batch 150.0 validation loss 5.736750861106835\n",
      "\n",
      "Batch 151.0 train loss 151.0 4.283612022399902\n",
      "\n",
      "Batch 151.0 validation loss 5.6620056758373245\n",
      "\n",
      "Batch 152.0 train loss 152.0 5.009315872192383\n",
      "\n",
      "Batch 152.0 validation loss 6.010430979611251\n",
      "\n",
      "Batch 153.0 train loss 153.0 6.682951831817627\n",
      "\n",
      "Batch 153.0 validation loss 6.0055427903612255\n"
     ]
    }
   ],
   "source": [
    "print('='*40)\n",
    "print('Start training')\n",
    "loss_all_list = []\n",
    "loss_batch_list = []\n",
    "val_batch_list = []\n",
    "\n",
    "train_loss_batch = 0\n",
    "for i in range(len(train_list)):\n",
    "    # 构造训练数据\n",
    "    pat = train_list[i]\n",
    "    train_sample = series_data_grouped.get_group(pat)\n",
    "    train_x_i, train_y_i = generate_sample(train_sample)\n",
    "    \n",
    "    train_x = np.array([train_x_i])\n",
    "    train_y = np.array([train_y_i])\n",
    "    \n",
    "#     print(f\"train_x: {train_x_i.shape}\")\n",
    "#     print(f\"train_y: {train_y_i.shape}\")\n",
    "    \n",
    "    train_loss = model_sequence.train_on_batch(train_x, train_y)\n",
    "    loss_all_list.append(train_loss)\n",
    "    \n",
    "    # loss 收敛很快，保存每50批次的loss，画出训练的曲线\n",
    "    if (i+1)%50 != 0:\n",
    "        train_loss_batch = train_loss_batch + train_loss\n",
    "        \n",
    "    else:\n",
    "        loss_batch_list.append(train_loss_batch/50)\n",
    "        print(f'\\nBatch {(i+1)/50} train loss {(i+1)/50} {train_loss_batch/50}')\n",
    "        train_loss_batch = 0\n",
    "        \n",
    "        # 全部验证集\n",
    "        val_list = []\n",
    "        for j in range(len(test_list)):\n",
    "            pat = test_list[j]\n",
    "            train_sample = series_data_grouped.get_group(pat)\n",
    "            train_x_i, train_y_i = generate_sample(train_sample)\n",
    "            \n",
    "            train_x = np.array([train_x_i])\n",
    "            train_y = np.array([train_y_i])\n",
    "            val_mae = model_sequence.evaluate(train_x, train_y, verbose=0)\n",
    "            val_list.append(val_mae)\n",
    "            \n",
    "        print(f'\\nBatch {(i+1)/50} validation loss {sum(val_list)/len(val_list)}')\n",
    "        val_batch_list.append(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(loss_batch_list))\n",
    "y = loss_batch_list\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
