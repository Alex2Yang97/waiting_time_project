{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'D:\\jupyter files\\waiting_time_project\\my_tools')\n",
    "import tools_for_os.for_df as ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把字符串转成datetime\n",
    "def str_to_Datetime(st):\n",
    "    dt = datetime.datetime.strptime(st, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "# 把datetime 转成字符串\n",
    "def Datetime_to_str(d):\n",
    "    str_date = d.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return str_date\n",
    "\n",
    "# 计算时间差\n",
    "def cal_time_inv(before, now):\n",
    "    before = str_to_Datetime(before)\n",
    "    now = str_to_Datetime(now)\n",
    "    if now >= before:\n",
    "        inv = (now - before).seconds\n",
    "        return inv\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这一部分的数据与处理和治疗时长预测的预处理相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "都需要将同一个appointment 里面的特征合并，同时将分类变量进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is (1788434, 35)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'D:\\\\jupyter files\\\\data_waiting_time_project\\\\preprocess_data\\\\'\n",
    "\n",
    "data_part1 = pd.read_csv(data_path + 'data_part1.csv', index_col = 0)\n",
    "data_part2 = pd.read_csv(data_path + 'data_part2.csv', index_col = 0)\n",
    "\n",
    "DATA = pd.merge(data_part1, data_part2, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "DATA.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'FractionNumber'], inplace = True)\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = ['Scheduled_duration', 'Actual_duration',\n",
    "               'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "               'MU_total', 'MUCoeff_total', 'Interval_scheduled']\n",
    "\n",
    "# RadiationId\n",
    "feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "                'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                'TreatmentOrientation', 'FractionNumber',\n",
    "                'UserName', 'CourseId', 'ResourceSerNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为需要进行onehot encoding，所以在拼接数据之前，先进行数据格式的处理\n",
    "for col in feature_cate:\n",
    "    try:\n",
    "        data_part1[col].fillna('Unknown', inplace = True)\n",
    "        data_part1[col] = data_part1[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data_part2[col].fillna('Unknown', inplace = True)\n",
    "        data_part2[col] = data_part2[col].astype(str)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for col in feature_num:\n",
    "    try:\n",
    "        data_part1.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data_part2.fillna(0, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# data_num = log1p(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one hot encoder\n",
    "# label_encoder_dxt_AliasName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_dxt_AliasName.fit(data_part1.dxt_AliasName.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_Sex = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_Sex.fit(data_part1.Sex.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_AliasSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_AliasSerNum.fit(data_part1.AliasSerNum.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_month = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_month.fit(data_part1.month.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_week = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_week.fit(data_part1.week.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_hour = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_hour.fit(data_part1.hour.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_DoctorSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_DoctorSerNum.fit(data_part1.DoctorSerNum.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_TreatmentOrientation = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_TreatmentOrientation.fit(data_part1.TreatmentOrientation.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_FractionNumber = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_FractionNumber.fit(data_part2.FractionNumber.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_UserName = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_UserName.fit(data_part2.UserName.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_CourseId = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_CourseId.fit(data_part2.CourseId.values.reshape(-1, 1))\n",
    "\n",
    "# label_encoder_ResourceSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_ResourceSerNum.fit(data_part2.ResourceSerNum.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_list(x):\n",
    "#     x = list(x)\n",
    "#     if len(x) == 1:\n",
    "#         return x[0]\n",
    "#     else:\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_appt = pd.DataFrame({})\n",
    "\n",
    "# print('Start cateorical features')\n",
    "# print('\\nStart PatientSerNum')\n",
    "# new_appt['PatientSerNum'] = data_part1.groupby('AppointmentSerNum').PatientSerNum.apply(set)\n",
    "# new_appt['PatientSerNum'] = new_appt['PatientSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start Sex')\n",
    "# new_appt['Sex'] = data_part1.groupby('AppointmentSerNum').Sex.apply(set)\n",
    "# new_appt['Sex'] = new_appt['Sex'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start DoctorSerNum')\n",
    "# new_appt['DoctorSerNum'] = data_part1.groupby('AppointmentSerNum').DoctorSerNum.apply(set)\n",
    "# new_appt['DoctorSerNum'] = new_appt['DoctorSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start date')\n",
    "# new_appt['date'] = data_part1.groupby('AppointmentSerNum').date.apply(set)\n",
    "# new_appt['date'] = new_appt['date'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start ScheduledStartTime')\n",
    "# new_appt['ScheduledStartTime'] = data_part1.groupby('AppointmentSerNum').ScheduledStartTime.apply(set)\n",
    "# new_appt['ScheduledStartTime'] = new_appt['ScheduledStartTime'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start ScheduledEndTime')\n",
    "# new_appt['ScheduledEndTime'] = data_part1.groupby('AppointmentSerNum').ScheduledEndTime.apply(set)\n",
    "# new_appt['ScheduledEndTime'] = new_appt['ScheduledEndTime'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start ActualStartDate')\n",
    "# new_appt['ActualStartDate'] = data_part1.groupby('AppointmentSerNum').ActualStartDate.apply(set)\n",
    "# new_appt['ActualStartDate'] = new_appt['ActualStartDate'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start ActualEndDate')\n",
    "# new_appt['ActualEndDate'] = data_part1.groupby('AppointmentSerNum').ActualEndDate.apply(set)\n",
    "# new_appt['ActualEndDate'] = new_appt['ActualEndDate'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start dxt_AliasName')\n",
    "# new_appt['dxt_AliasName'] = data_part1.groupby('AppointmentSerNum').dxt_AliasName.apply(set)\n",
    "# new_appt['dxt_AliasName'] = new_appt['dxt_AliasName'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start AliasSerNum')\n",
    "# new_appt['AliasSerNum'] = data_part1.groupby('AppointmentSerNum').AliasSerNum.apply(set)\n",
    "# new_appt['AliasSerNum'] = new_appt['AliasSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start CourseSerNum')\n",
    "# new_appt['CourseSerNum'] = data_part1.groupby('AppointmentSerNum').CourseSerNum.apply(set)\n",
    "# new_appt['CourseSerNum'] = new_appt['CourseSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start PlanSerNum')\n",
    "# new_appt['PlanSerNum'] = data_part1.groupby('AppointmentSerNum').PlanSerNum.apply(set)\n",
    "# new_appt['PlanSerNum'] = new_appt['PlanSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start TreatmentOrientation')\n",
    "# new_appt['TreatmentOrientation'] = data_part1.groupby('AppointmentSerNum').TreatmentOrientation.apply(set)\n",
    "# new_appt['TreatmentOrientation'] = new_appt['TreatmentOrientation'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start month')\n",
    "# new_appt['month'] = data_part1.groupby('AppointmentSerNum').month.apply(set)\n",
    "# new_appt['month'] = new_appt['month'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start week')\n",
    "# new_appt['week'] = data_part1.groupby('AppointmentSerNum').week.apply(set)\n",
    "# new_appt['week'] = new_appt['week'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start hour')\n",
    "# new_appt['hour'] = data_part1.groupby('AppointmentSerNum').hour.apply(set)\n",
    "# new_appt['hour'] = new_appt['hour'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start AppointmentSerNum')\n",
    "# new_appt['AppointmentSerNum'] = new_appt.index.tolist()\n",
    "\n",
    "\n",
    "# print('Start numberical features')\n",
    "# print('\\nStart age')\n",
    "# new_appt['age'] = data_part1.groupby('AppointmentSerNum').age.mean()\n",
    "\n",
    "# print('Start Scheduled_duration')\n",
    "# new_appt['Scheduled_duration'] = data_part1.groupby('AppointmentSerNum').Scheduled_duration.mean()\n",
    "\n",
    "# print('Start Actual_duration')\n",
    "# new_appt['Actual_duration'] = data_part1.groupby('AppointmentSerNum').Actual_duration.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_treat = pd.DataFrame({})\n",
    "\n",
    "# print('Start categorical features')\n",
    "# print('\\nStart FractionNumber')\n",
    "# new_treat['FractionNumber'] = data_part2.groupby(['PatientSerNum', 'date']).FractionNumber.apply(set)\n",
    "# new_treat['FractionNumber'] = new_treat['FractionNumber'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start UserName')\n",
    "# new_treat['UserName'] = data_part2.groupby(['PatientSerNum', 'date']).UserName.apply(set)\n",
    "# new_treat['UserName'] = new_treat['UserName'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start RadiationSerNum')\n",
    "# new_treat['RadiationSerNum'] = data_part2.groupby(['PatientSerNum', 'date']).RadiationSerNum.apply(set)\n",
    "# new_treat['RadiationSerNum'] = new_treat['RadiationSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start RadiationId')\n",
    "# new_treat['RadiationId'] = data_part2.groupby(['PatientSerNum', 'date']).RadiationId.apply(set)\n",
    "# new_treat['RadiationId'] = new_treat['RadiationId'].apply(lambda x: get_list(x))\n",
    "\n",
    "# # print('Start ResourceSerNum')\n",
    "# # new_treat['ResourceSerNum'] = data_part2.groupby(['PatientSerNum', 'date']).ResourceSerNum.apply(set)\n",
    "# # new_treat['ResourceSerNum'] = new_treat['ResourceSerNum'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start CourseId')\n",
    "# new_treat['CourseId'] = data_part2.groupby(['PatientSerNum', 'date']).CourseId.apply(set)\n",
    "# new_treat['CourseId'] = new_treat['CourseId'].apply(lambda x: get_list(x))\n",
    "\n",
    "# print('Start PatientSerNum')\n",
    "# new_treat['PatientSerNum'] = new_treat.index.get_level_values(level = 0).tolist()\n",
    "\n",
    "# print('Start date')\n",
    "# new_treat['date'] = new_treat.index.get_level_values(level = 1).tolist()\n",
    "\n",
    "\n",
    "# print('Start numberical features')\n",
    "# print('\\nStart ImagesTaken_total')\n",
    "# new_treat['ImagesTaken_total'] = data_part2.groupby(['PatientSerNum', 'date']).ImagesTaken.sum()\n",
    "\n",
    "# print('Start MU_total')\n",
    "# new_treat['MU_total'] = data_part2.groupby(['PatientSerNum', 'date']).MU.sum()\n",
    "\n",
    "# print('Start MUCoeff_total')\n",
    "# new_treat['MUCoeff_total'] = data_part2.groupby(['PatientSerNum', 'date']).MUCoeff.sum()\n",
    "\n",
    "# print('Start TreatmentTime_total')\n",
    "# new_treat['TreatmentTime_total'] = data_part2.groupby(['PatientSerNum', 'date']).TreatmentTime.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_treat.drop('ResourceSerNum', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_appt.reset_index(drop = True, inplace = True)\n",
    "new_treat.reset_index(drop = True, inplace = True)\n",
    "\n",
    "print(f'The shape of new_appt is {new_appt.shape}')\n",
    "print(f'The shape of new_treat is {new_treat.shape}')\n",
    "\n",
    "DATA = pd.merge(new_appt, new_treat, on = ['PatientSerNum', 'date'], how = 'inner')\n",
    "DATA.sort_values(by = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime'], inplace = True)\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pd.merge(DATA, data_re_appt[['AppointmentSerNum', 'ResourceSerNum']], on = 'AppointmentSerNum', how = 'inner')\n",
    "print(f'The shape of data is {DATA.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The shape of data is {DATA.shape}')\n",
    "DATA_ = DATA[(DATA.Actual_duration >= 10) &\n",
    "             (DATA.Actual_duration <= 60)]\n",
    "print(f'The shape of data is {DATA_.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data_resource (477, 6)\n",
      "The shape of data_re_appt (475920, 7)\n",
      "The shape of data_appt (1074478, 17)\n",
      "The shape of data_pl (206855, 9)\n",
      "The shape of data_plmh (2333039, 10)\n"
     ]
    }
   ],
   "source": [
    "sql_re = \"\"\"SELECT * FROM resource\"\"\"\n",
    "data_re_ = ml_df.get_df_from_sql(sql_re)\n",
    "print(f'The shape of data_resource {data_re_.shape}')\n",
    "sql_re_appt = \"\"\"SELECT * FROM resourceappointment\"\"\"\n",
    "data_re_appt_ = ml_df.get_df_from_sql(sql_re_appt)\n",
    "print(f'The shape of data_re_appt {data_re_appt_.shape}')\n",
    "sql_appt = \"\"\"SELECT * FROM appointment\"\"\"\n",
    "data_appt_ = ml_df.get_df_from_sql(sql_appt)\n",
    "print(f'The shape of data_appt {data_appt_.shape}')\n",
    "sql_pl = \"\"\"SELECT * FROM patientlocation\"\"\"\n",
    "data_pl_ = ml_df.get_df_from_sql(sql_pl)\n",
    "print(f'The shape of data_pl {data_pl_.shape}')\n",
    "sql_plmh = \"\"\"SELECT * FROM patientlocationmh\"\"\"\n",
    "data_plmh_ = ml_df.get_df_from_sql(sql_plmh)\n",
    "print(f'The shape of data_plmh {data_plmh_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop columns\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('Drop columns')\n",
    "    data_appt_.drop(columns = ['LastUpdated'], inplace = True)\n",
    "    data_re_.drop(columns = ['LastUpdated'], inplace = True)\n",
    "    data_re_appt_.drop('LastUpdated', axis = 1, inplace = True)\n",
    "    data_pl_.drop(columns = ['LastUpdated'], inplace = True)\n",
    "    data_plmh_.drop(columns = ['LastUpdated'], inplace = True)\n",
    "except:\n",
    "    print('Finish droppping columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data_appt (1074478, 16)\n",
      "The shape of data_appt (370299, 16)\n",
      "Merge data_appt and data_re_appt\n",
      "The shape of appt_re_appt (165512, 20)\n",
      "\n",
      "Merge data_re\n",
      "The shape of appt_loc (165512, 23)\n",
      "\n",
      "Merge data_pl\n",
      "The shape of appt_loc_pl (165512, 29)\n",
      "\n",
      "Get Treat_Date\n",
      "The shape of room_infomation (165512, 8)\n"
     ]
    }
   ],
   "source": [
    "data_re = data_re_.copy()\n",
    "data_re_appt = data_re_appt_.copy()\n",
    "data_appt = data_appt_.copy()\n",
    "data_pl = data_pl_.copy()\n",
    "data_plmh = data_plmh_.copy()\n",
    "\n",
    "\n",
    "print(f'The shape of data_appt {data_appt.shape}')\n",
    "data_appt = data_appt[\n",
    "    (data_appt.ActualStartDate != datetime.datetime(1970, 1, 1, 0, 0)) &\n",
    "    (data_appt.ActualEndDate != datetime.datetime(1970, 1, 1, 0, 0)) &\n",
    "    (data_appt.ActualStartDate != '0000-00-00 00:00:00')]\n",
    "print(f'The shape of data_appt {data_appt.shape}')\n",
    "\n",
    "# 已经检查过，一个Appointment 里面只有一个AliasSerNum\n",
    "# 一个AliasSerNum 对应多个ResourceSerNum\n",
    "# 一个ResourceSerNum 对应多个AppointmentSerNum\n",
    "print('Merge data_appt and data_re_appt')\n",
    "appt_re_appt = pd.merge(data_appt, data_re_appt, on = ['AppointmentSerNum', 'AliasSerNum'], how = 'inner')\n",
    "print(f'The shape of appt_re_appt {appt_re_appt.shape}')\n",
    "appt_re_appt.drop('AliasSerNum', axis = 1, inplace = True)\n",
    "\n",
    "print('\\nMerge data_re')\n",
    "appt_loc = pd.merge(data_re, appt_re_appt, on = ['ResourceSerNum'], how = 'inner')\n",
    "print(f'The shape of appt_loc {appt_loc.shape}')\n",
    "\n",
    "print('\\nMerge data_pl')\n",
    "data_pl.drop('AliasSerNum', axis = 1, inplace = True)\n",
    "appt_loc_pl = pd.merge(data_pl, appt_loc, on = ['AppointmentSerNum'], how = 'right')\n",
    "print(f'The shape of appt_loc_pl {appt_loc_pl.shape}')\n",
    "\n",
    "print('\\nGet Treat_Date')\n",
    "appt_loc_pl['Treat_Date'] = appt_loc_pl.apply(lambda x: x.ActualStartDate.strftime(\"%Y-%m-%d\"), axis = 1)\n",
    "\n",
    "appt_loc_pl = appt_loc_pl[[\n",
    "    'AppointmentSerNum', 'PatientSerNum', 'AliasExpressionSerNum',\n",
    "    'ScheduledStartTime', 'ScheduledEndTime',\n",
    "    'ActualStartDate', 'ActualEndDate',\n",
    "    'ResourceSerNum']]\n",
    "print(f'The shape of room_infomation {appt_loc_pl.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppointmentSerNum</th>\n",
       "      <th>PatientSerNum</th>\n",
       "      <th>AliasExpressionSerNum</th>\n",
       "      <th>ScheduledStartTime</th>\n",
       "      <th>ResourceSerNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849926</td>\n",
       "      <td>38996</td>\n",
       "      <td>1505</td>\n",
       "      <td>2015-10-19 14:00:00</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>849927</td>\n",
       "      <td>38996</td>\n",
       "      <td>1505</td>\n",
       "      <td>2015-10-20 13:45:00</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849928</td>\n",
       "      <td>38996</td>\n",
       "      <td>1505</td>\n",
       "      <td>2015-10-21 15:30:00</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>849929</td>\n",
       "      <td>38996</td>\n",
       "      <td>1505</td>\n",
       "      <td>2015-10-22 14:00:00</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>849930</td>\n",
       "      <td>38996</td>\n",
       "      <td>1505</td>\n",
       "      <td>2015-10-23 13:00:00</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AppointmentSerNum  PatientSerNum  AliasExpressionSerNum  \\\n",
       "0             849926          38996                   1505   \n",
       "1             849927          38996                   1505   \n",
       "2             849928          38996                   1505   \n",
       "3             849929          38996                   1505   \n",
       "4             849930          38996                   1505   \n",
       "\n",
       "    ScheduledStartTime  ResourceSerNum  \n",
       "0  2015-10-19 14:00:00             176  \n",
       "1  2015-10-20 13:45:00             177  \n",
       "2  2015-10-21 15:30:00             176  \n",
       "3  2015-10-22 14:00:00             176  \n",
       "4  2015-10-23 13:00:00             176  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appt_loc_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d38344baf065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mappt_loc_pl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ScheduledStartTime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappt_loc_pl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ScheduledStartTime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDatetime_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m room_info = pd.merge(appt_loc_pl, DATA_, \n\u001b[0m\u001b[0;32m      6\u001b[0m                      on = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'ResourceSerNum'], how = 'inner')\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'The shape of room_infomation {room_info.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_' is not defined"
     ]
    }
   ],
   "source": [
    "appt_loc_pl = appt_loc_pl[[\n",
    "    'AppointmentSerNum', 'PatientSerNum', 'AliasExpressionSerNum', 'ScheduledStartTime', 'ResourceSerNum']]\n",
    "appt_loc_pl['ScheduledStartTime'] = appt_loc_pl['ScheduledStartTime'].apply(lambda x: Datetime_to_str(x))\n",
    "\n",
    "room_info = pd.merge(appt_loc_pl, DATA_, \n",
    "                     on = ['PatientSerNum', 'AppointmentSerNum', 'ScheduledStartTime', 'ResourceSerNum'], how = 'inner')\n",
    "print(f'The shape of room_infomation {room_info.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one hot encoder\n",
    "# label_encoder_AliasExpressionSerNum = preprocessing.OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# label_encoder_AliasExpressionSerNum.fit(room_info.AliasExpressionSerNum.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_info_grouped = room_info.groupby(['ResourceSerNum', 'date'])\n",
    "\n",
    "room_count = room_info_grouped.count()\n",
    "room_seq = room_count[room_count.PatientSerNum > 1].index.tolist()\n",
    "room_one = room_count[room_count.PatientSerNum == 1].index.tolist()\n",
    "print(f'room_seq {len(room_seq)}')\n",
    "print(f'room_one {len(room_one)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_seq(room):\n",
    "    room.sort_values(by = 'ActualStartDate', inplace = True)\n",
    "\n",
    "    room['pre_ActualEndDate'] = room.ActualEndDate.shift(periods = 1, fill_value = room.ActualStartDate.iloc[0])\n",
    "    room['Transfer_duration'] = room.apply(lambda x: cal_time_inv(x.pre_ActualEndDate,x.ActualStartDate), axis = 1)\n",
    "    room['Interval_number'] = room.apply(lambda x: int(x.Transfer_duration / 60 / 15), axis = 1)\n",
    "    \n",
    "    label_d = room.Transfer_duration.iloc[-1]\n",
    "    label_n = room.Interval_number.iloc[-1]\n",
    "    \n",
    "    room.Actual_duration.iloc[-1] = 0\n",
    "    room.Transfer_duration.iloc[-1] = 0\n",
    "    \n",
    "#     room.Transfer_duration.iloc[-1] = cal_time_inv(room.ActualEndDate.iloc[-2], room.ScheduledStartTime.iloc[-1])\n",
    "    \n",
    "    room.Interval_number.iloc[-1] = int(room.Transfer_duration.iloc[-1] /60 / 15)\n",
    "    return room, label_d, label_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['AppointmentSerNum', 'PatientSerNum', \n",
    "#  'ScheduledStartTime', 'ResourceSerNum', \n",
    "#  'date', 'ScheduledEndTime',\n",
    "#  'ActualStartDate', 'ActualEndDate', \n",
    "#  'CourseSerNum', 'PlanSerNum',\n",
    "#  'RadiationSerNum', 'RadiationId',\n",
    "#  'pre_ActualEndDate']\n",
    "\n",
    "\n",
    "# RadiationId\n",
    "feature_cate = ['dxt_AliasName', 'Sex', 'AliasSerNum',\n",
    "                'month', 'week', 'hour', 'DoctorSerNum', \n",
    "                'TreatmentOrientation', 'FractionNumber',\n",
    "                'UserName', 'CourseId', 'ResourceSerNum', \n",
    "                'AliasExpressionSerNum']\n",
    "\n",
    "feature_num = ['Scheduled_duration', 'Actual_duration',\n",
    "               'age', 'TreatmentTime_total', 'ImagesTaken_total',\n",
    "               'MU_total', 'MUCoeff_total',\n",
    "               'Transfer_duration', 'Interval_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(room, feature_num = feature_num):\n",
    "    \n",
    "    # 对分类变量进行one-hot encoding处理\n",
    "    encode_cate = pd.DataFrame({})\n",
    "    \n",
    "    # 这个地方将Sex 作为序列的一部分，并不是在最后的隐藏层进行合并\n",
    "    encode_cate['Sex'] = room['Sex'].apply(\n",
    "        lambda x: sum(label_encoder_Sex.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.vstack(encode_cate.Sex.tolist())\n",
    "\n",
    "    encode_cate['dxt_AliasName'] = room['dxt_AliasName'].apply(\n",
    "        lambda x: sum(label_encoder_dxt_AliasName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.dxt_AliasName.tolist())))\n",
    "\n",
    "    encode_cate['AliasSerNum'] = room['AliasSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_AliasSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.AliasSerNum.tolist())))\n",
    "\n",
    "    encode_cate['month'] = room['month'].apply(\n",
    "        lambda x: sum(label_encoder_month.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.month.tolist())))\n",
    "\n",
    "    encode_cate['week'] = room['week'].apply(\n",
    "        lambda x: sum(label_encoder_week.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.week.tolist())))\n",
    "\n",
    "    encode_cate['hour'] = room['hour'].apply(\n",
    "        lambda x: sum(label_encoder_hour.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.hour.tolist())))\n",
    "\n",
    "    encode_cate['DoctorSerNum'] = room['DoctorSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_DoctorSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.DoctorSerNum.tolist())))\n",
    "\n",
    "    encode_cate['TreatmentOrientation'] = room['TreatmentOrientation'].apply(\n",
    "        lambda x: sum(label_encoder_TreatmentOrientation.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.TreatmentOrientation.tolist())))\n",
    "\n",
    "    encode_cate['FractionNumber'] = room['FractionNumber'].apply(\n",
    "        lambda x: sum(label_encoder_FractionNumber.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.FractionNumber.tolist())))\n",
    "\n",
    "    encode_cate['UserName'] = room['UserName'].apply(\n",
    "        lambda x: sum(label_encoder_UserName.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.UserName.tolist())))\n",
    "\n",
    "    encode_cate['CourseId'] = room['CourseId'].apply(\n",
    "        lambda x: sum(label_encoder_CourseId.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.CourseId.tolist())))\n",
    "\n",
    "    encode_cate['ResourceSerNum'] = room['ResourceSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_ResourceSerNum.transform(np.array(str(x)).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.ResourceSerNum.tolist())))\n",
    "    \n",
    "    encode_cate['AliasExpressionSerNum'] = room['AliasExpressionSerNum'].apply(\n",
    "        lambda x: sum(label_encoder_AliasExpressionSerNum.transform(np.array(x).reshape(-1,1))))\n",
    "    train_x = np.hstack((train_x, np.vstack(encode_cate.AliasExpressionSerNum.tolist())))\n",
    "    \n",
    "    # 将数值变量和非数值变量进行合并\n",
    "    train_num = room[feature_num]\n",
    "    train_x = np.hstack((train_x, train_num))\n",
    "    \n",
    "#     # 需要满足序列长度的要求，因此对于短序列进行补零操作\n",
    "#     zeros = np.zeros((APPT_LEN - train_x.shape[0], FEATURE_LEN))\n",
    "#     train_x = np.vstack((zeros, train_x))\n",
    "    \n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LEN = 463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 不指定时间戳长度\n",
    "# model_sequence = Sequential()\n",
    "# model_sequence.add(layers.LSTM(\n",
    "#     batch_input_shape = (None , None, FEATURE_LEN),\n",
    "#     output_dim = 128,\n",
    "#     dropout=0.1,\n",
    "#     recurrent_dropout=0.5,\n",
    "#     return_sequences=False,\n",
    "# ))\n",
    "\n",
    "# # model_sequence.add(layers.LSTM(\n",
    "# #     output_dim = 32,\n",
    "# #     return_sequences = False\n",
    "# # ))\n",
    "# # # stateful = True 本次batch的参数返回到下一次的训练中\n",
    "\n",
    "# model_sequence.add(layers.Dense(32))\n",
    "\n",
    "# model_sequence.add(layers.Dense(1))\n",
    "\n",
    "# adam = optimizers.Adam(lr=0.001)\n",
    "# model_sequence.compile(\n",
    "#     optimizer = adam,\n",
    "#     loss = 'mae'\n",
    "# )\n",
    "\n",
    "# model_sequence.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScheduledStartTime</th>\n",
       "      <th>ScheduledEndTime</th>\n",
       "      <th>ActualStartDate</th>\n",
       "      <th>ActualEndDate</th>\n",
       "      <th>Scheduled_duration</th>\n",
       "      <th>Actual_duration</th>\n",
       "      <th>pre_ActualEndDate</th>\n",
       "      <th>Transfer_duration</th>\n",
       "      <th>Interval_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125504</th>\n",
       "      <td>2015-06-17 08:00:00</td>\n",
       "      <td>2015-06-17 08:15:00</td>\n",
       "      <td>2015-06-17 07:46:00</td>\n",
       "      <td>2015-06-17 08:03:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2015-06-17 07:46:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125384</th>\n",
       "      <td>2015-06-17 08:15:00</td>\n",
       "      <td>2015-06-17 08:30:00</td>\n",
       "      <td>2015-06-17 08:16:00</td>\n",
       "      <td>2015-06-17 08:30:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2015-06-17 08:03:00</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125576</th>\n",
       "      <td>2015-06-17 09:00:00</td>\n",
       "      <td>2015-06-17 09:15:00</td>\n",
       "      <td>2015-06-17 08:37:00</td>\n",
       "      <td>2015-06-17 08:58:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2015-06-17 08:30:00</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125466</th>\n",
       "      <td>2015-06-17 08:30:00</td>\n",
       "      <td>2015-06-17 08:45:00</td>\n",
       "      <td>2015-06-17 08:59:00</td>\n",
       "      <td>2015-06-17 09:17:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2015-06-17 08:58:00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125650</th>\n",
       "      <td>2015-06-17 08:45:00</td>\n",
       "      <td>2015-06-17 09:00:00</td>\n",
       "      <td>2015-06-17 09:18:00</td>\n",
       "      <td>2015-06-17 09:31:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2015-06-17 09:17:00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125563</th>\n",
       "      <td>2015-06-17 09:30:00</td>\n",
       "      <td>2015-06-17 09:45:00</td>\n",
       "      <td>2015-06-17 09:31:00</td>\n",
       "      <td>2015-06-17 09:45:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2015-06-17 09:31:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125706</th>\n",
       "      <td>2015-06-17 10:15:00</td>\n",
       "      <td>2015-06-17 10:30:00</td>\n",
       "      <td>2015-06-17 10:00:00</td>\n",
       "      <td>2015-06-17 10:17:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2015-06-17 09:45:00</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125667</th>\n",
       "      <td>2015-06-17 11:15:00</td>\n",
       "      <td>2015-06-17 11:30:00</td>\n",
       "      <td>2015-06-17 10:23:00</td>\n",
       "      <td>2015-06-17 10:49:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2015-06-17 10:17:00</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125469</th>\n",
       "      <td>2015-06-17 11:45:00</td>\n",
       "      <td>2015-06-17 12:15:00</td>\n",
       "      <td>2015-06-17 11:59:00</td>\n",
       "      <td>2015-06-17 12:24:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2015-06-17 10:49:00</td>\n",
       "      <td>4200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125731</th>\n",
       "      <td>2015-06-17 11:15:00</td>\n",
       "      <td>2015-06-17 11:30:00</td>\n",
       "      <td>2015-06-17 12:26:00</td>\n",
       "      <td>2015-06-17 12:44:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2015-06-17 12:24:00</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125735</th>\n",
       "      <td>2015-06-17 12:15:00</td>\n",
       "      <td>2015-06-17 12:30:00</td>\n",
       "      <td>2015-06-17 12:45:00</td>\n",
       "      <td>2015-06-17 13:03:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2015-06-17 12:44:00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125381</th>\n",
       "      <td>2015-06-17 14:45:00</td>\n",
       "      <td>2015-06-17 15:00:00</td>\n",
       "      <td>2015-06-17 14:28:00</td>\n",
       "      <td>2015-06-17 14:41:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2015-06-17 13:03:00</td>\n",
       "      <td>5100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125071</th>\n",
       "      <td>2015-06-17 14:15:00</td>\n",
       "      <td>2015-06-17 14:30:00</td>\n",
       "      <td>2015-06-17 14:42:00</td>\n",
       "      <td>2015-06-17 14:56:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2015-06-17 14:41:00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125586</th>\n",
       "      <td>2015-06-17 14:30:00</td>\n",
       "      <td>2015-06-17 14:45:00</td>\n",
       "      <td>2015-06-17 15:01:00</td>\n",
       "      <td>2015-06-17 15:13:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2015-06-17 14:56:00</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125634</th>\n",
       "      <td>2015-06-17 15:30:00</td>\n",
       "      <td>2015-06-17 15:45:00</td>\n",
       "      <td>2015-06-17 15:14:00</td>\n",
       "      <td>2015-06-17 15:36:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-06-17 15:13:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ScheduledStartTime     ScheduledEndTime      ActualStartDate  \\\n",
       "125504  2015-06-17 08:00:00  2015-06-17 08:15:00  2015-06-17 07:46:00   \n",
       "125384  2015-06-17 08:15:00  2015-06-17 08:30:00  2015-06-17 08:16:00   \n",
       "125576  2015-06-17 09:00:00  2015-06-17 09:15:00  2015-06-17 08:37:00   \n",
       "125466  2015-06-17 08:30:00  2015-06-17 08:45:00  2015-06-17 08:59:00   \n",
       "125650  2015-06-17 08:45:00  2015-06-17 09:00:00  2015-06-17 09:18:00   \n",
       "125563  2015-06-17 09:30:00  2015-06-17 09:45:00  2015-06-17 09:31:00   \n",
       "125706  2015-06-17 10:15:00  2015-06-17 10:30:00  2015-06-17 10:00:00   \n",
       "125667  2015-06-17 11:15:00  2015-06-17 11:30:00  2015-06-17 10:23:00   \n",
       "125469  2015-06-17 11:45:00  2015-06-17 12:15:00  2015-06-17 11:59:00   \n",
       "125731  2015-06-17 11:15:00  2015-06-17 11:30:00  2015-06-17 12:26:00   \n",
       "125735  2015-06-17 12:15:00  2015-06-17 12:30:00  2015-06-17 12:45:00   \n",
       "125381  2015-06-17 14:45:00  2015-06-17 15:00:00  2015-06-17 14:28:00   \n",
       "125071  2015-06-17 14:15:00  2015-06-17 14:30:00  2015-06-17 14:42:00   \n",
       "125586  2015-06-17 14:30:00  2015-06-17 14:45:00  2015-06-17 15:01:00   \n",
       "125634  2015-06-17 15:30:00  2015-06-17 15:45:00  2015-06-17 15:14:00   \n",
       "\n",
       "              ActualEndDate  Scheduled_duration  Actual_duration  \\\n",
       "125504  2015-06-17 08:03:00                15.0             17.0   \n",
       "125384  2015-06-17 08:30:00                15.0             14.0   \n",
       "125576  2015-06-17 08:58:00                15.0             21.0   \n",
       "125466  2015-06-17 09:17:00                15.0             18.0   \n",
       "125650  2015-06-17 09:31:00                15.0             13.0   \n",
       "125563  2015-06-17 09:45:00                15.0             14.0   \n",
       "125706  2015-06-17 10:17:00                15.0             17.0   \n",
       "125667  2015-06-17 10:49:00                15.0             26.0   \n",
       "125469  2015-06-17 12:24:00                30.0             25.0   \n",
       "125731  2015-06-17 12:44:00                15.0             18.0   \n",
       "125735  2015-06-17 13:03:00                15.0             18.0   \n",
       "125381  2015-06-17 14:41:00                15.0             13.0   \n",
       "125071  2015-06-17 14:56:00                15.0             14.0   \n",
       "125586  2015-06-17 15:13:00                15.0             12.0   \n",
       "125634  2015-06-17 15:36:00                15.0              0.0   \n",
       "\n",
       "          pre_ActualEndDate  Transfer_duration  Interval_number  \n",
       "125504  2015-06-17 07:46:00                  0                0  \n",
       "125384  2015-06-17 08:03:00                780                0  \n",
       "125576  2015-06-17 08:30:00                420                0  \n",
       "125466  2015-06-17 08:58:00                 60                0  \n",
       "125650  2015-06-17 09:17:00                 60                0  \n",
       "125563  2015-06-17 09:31:00                  0                0  \n",
       "125706  2015-06-17 09:45:00                900                1  \n",
       "125667  2015-06-17 10:17:00                360                0  \n",
       "125469  2015-06-17 10:49:00               4200                4  \n",
       "125731  2015-06-17 12:24:00                120                0  \n",
       "125735  2015-06-17 12:44:00                 60                0  \n",
       "125381  2015-06-17 13:03:00               5100                5  \n",
       "125071  2015-06-17 14:41:00                 60                0  \n",
       "125586  2015-06-17 14:56:00                300                0  \n",
       "125634  2015-06-17 15:13:00                  0                0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room = room_info_grouped.get_group(room_seq[3])\n",
    "room, label_d, label_n = generate_room_seq(room)\n",
    "train_x = generate_sample(room, feature_num = feature_num)\n",
    "# # 'pre_ActualEndDate' 'Transfer_duration', 'Interval_number'\n",
    "room[['ScheduledStartTime', 'ScheduledEndTime', 'ActualStartDate', 'ActualEndDate', 'Scheduled_duration', 'Actual_duration', 'pre_ActualEndDate', 'Transfer_duration', 'Interval_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-81b858fa4912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# 构造训练数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mroom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroom_info_grouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mroom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_room_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-205-913d69582d62>\u001b[0m in \u001b[0;36mgenerate_room_seq\u001b[1;34m(room)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_room_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mroom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ActualStartDate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mroom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_ActualEndDate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActualEndDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperiods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActualStartDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mroom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Transfer_duration'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcal_time_inv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_ActualEndDate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActualStartDate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[0;32m   4730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4732\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4733\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4734\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_update_inplace\u001b[1;34m(self, result, verify_is_copy)\u001b[0m\n\u001b[0;32m   3854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3855\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3856\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_is_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'referant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclear\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_result_batch = 0\n",
    "room_seq = shuffle(room_seq)\n",
    "\n",
    "for i in range(len(room_seq)):\n",
    "    \n",
    "    # 构造训练数据\n",
    "    room = room_info_grouped.get_group(room_seq[i])\n",
    "    room, label_d, label_n = generate_room_seq(room)\n",
    "    train_x = generate_sample(room)\n",
    "    \n",
    "    train_x = np.array([train_x])\n",
    "    train_y = np.array([[label_d]])\n",
    "    train_result = model_sequence.train_on_batch(train_x, train_y)\n",
    "    \n",
    "#     print(label_d)\n",
    "#     print(train_result)\n",
    "    if (i+1)%50 == 0:\n",
    "        print(f'\\nBatch {(i+1)/50} {train_result_batch/50}')\n",
    "        train_result_batch = 0\n",
    "    else:\n",
    "        train_result_batch = train_result_batch + train_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
